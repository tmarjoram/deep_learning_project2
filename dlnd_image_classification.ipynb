{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/cifar/cifar-10-python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 4:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1003, 1: 963, 2: 1041, 3: 976, 4: 1004, 5: 1021, 6: 1004, 7: 981, 8: 1024, 9: 983}\n",
      "First 20 Labels: [0, 6, 0, 2, 7, 2, 1, 2, 4, 1, 5, 6, 6, 3, 1, 3, 5, 5, 8, 1]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 13 Max Value: 169\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 2 Name: bird\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBD0ANCboAaAxQQ8AjQl6AGjs/wC42Lcq2cSEgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d5375a2780>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 4\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return x/256\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    result = np.zeros((len(x),10))\n",
    "    for i, label in enumerate(x):\n",
    "        result[i][label] = 1\n",
    "                              \n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))\n",
    "\n",
    "#valid_features[:1], valid_labels[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None,image_shape[0],image_shape[1],image_shape[2]], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.uint8, shape=[None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # Convolution Weights and Bias\n",
    "    conv_weights = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], \n",
    "                                                  x_tensor.get_shape().as_list()[3], conv_num_outputs ],stddev=0.1))\n",
    "    conv_bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    # Convolution Layer\n",
    "    conv_layer=tf.nn.conv2d(x_tensor, conv_weights, strides=[1,conv_strides[0], conv_strides[1],1], padding='SAME')\n",
    "    conv_layer=tf.nn.bias_add(conv_layer,conv_bias)\n",
    "    conv_layer=tf.nn.relu(conv_layer)\n",
    "    \n",
    "    #Pooling Layer\n",
    "    pooling_layer=tf.nn.max_pool(conv_layer, ksize=[1,pool_ksize[0], pool_ksize[1],1], \n",
    "                                 strides=[1,pool_strides[0], pool_strides[1],1], padding='SAME')\n",
    "    \n",
    "    return pooling_layer \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape_l = x_tensor.get_shape().as_list()\n",
    "    fc1 = tf.reshape(x_tensor, shape=[-1, shape_l[1]*shape_l[2]*shape_l[3]])\n",
    "    return fc1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    shape_l = x_tensor.get_shape().as_list()\n",
    "    weights = tf.Variable(tf.truncated_normal([shape_l[1], num_outputs],stddev=0.1))\n",
    "    bias = tf.Variable(tf.random_normal([num_outputs]))\n",
    "\n",
    "    # Logits - xW + b\n",
    "    fc = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    fc = tf.nn.relu(fc)\n",
    "\n",
    "    return fc\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    shape_l = x_tensor.get_shape().as_list()\n",
    "    weights = tf.Variable(tf.truncated_normal([shape_l[1], num_outputs],stddev=0.1))\n",
    "    bias = tf.Variable(tf.random_normal([num_outputs]))\n",
    "\n",
    "    # Logits - xW + b\n",
    "    return tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape (?, 32, 32, 3)\n",
      "1st covnet shape (?, 16, 16, 32)\n",
      "2nd covnet shape (?, 8, 8, 128)\n",
      "3rd covnet shape (?, 4, 4, 512)\n",
      "Flatten shape (?, 8192)\n",
      "Fully Con 1 shape (?, 2048)\n",
      "Fully Con 2 shape (?, 512)\n",
      "Output shape (?, 10)\n",
      "x shape (?, 32, 32, 3)\n",
      "1st covnet shape (?, 16, 16, 32)\n",
      "2nd covnet shape (?, 8, 8, 128)\n",
      "3rd covnet shape (?, 4, 4, 512)\n",
      "Flatten shape (?, 8192)\n",
      "Fully Con 1 shape (?, 2048)\n",
      "Fully Con 2 shape (?, 512)\n",
      "Output shape (?, 10)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    print (\"x shape {}\".format(x.get_shape()))\n",
    "    \n",
    "    cov_net = conv2d_maxpool(x, 32,(3,3), (2,2), (3,3), (1,1))\n",
    "    print (\"1st covnet shape {}\".format(cov_net.get_shape()))\n",
    "    \n",
    "    cov_net = conv2d_maxpool(cov_net, 128,(3,3), (2,2), (3,3), (1,1)) \n",
    "    print (\"2nd covnet shape {}\".format(cov_net.get_shape()))\n",
    "           \n",
    "    cov_net = conv2d_maxpool(cov_net, 512,(2,2), (2,2), (2,2), (1,1))\n",
    "    print (\"3rd covnet shape {}\".format(cov_net.get_shape()))\n",
    "           \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    cov_net=flatten(cov_net)\n",
    "    print (\"Flatten shape {}\".format(cov_net.get_shape()))\n",
    "\n",
    "    cov_net = tf.nn.dropout(cov_net,keep_prob)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    cov_net = fully_conn(cov_net, 2048) \n",
    "    print (\"Fully Con 1 shape {}\".format(cov_net.get_shape()))\n",
    "   \n",
    "    cov_net = tf.nn.dropout(cov_net,keep_prob)\n",
    "\n",
    "    cov_net = fully_conn(cov_net, 512) \n",
    "    print (\"Fully Con 2 shape {}\".format(cov_net.get_shape()))\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    cov_net = output(cov_net,10)\n",
    "    print (\"Output shape {}\".format(cov_net.get_shape()))\n",
    "\n",
    "    # TODO: return output\n",
    "    return cov_net\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    t_loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "\n",
    "    v_loss = session.run(cost, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.})\n",
    "    v_acc = session.run(accuracy, feed_dict={\n",
    "        x: valid_features,\n",
    "        y: valid_labels,\n",
    "        keep_prob: 1.})    \n",
    "    \n",
    "    print('Train Loss: {:>8.4f} Valid Loss: {:>8.4f} Valid Accuracy: {:.6f} '.format(\n",
    "        t_loss,\n",
    "        v_loss,\n",
    "        v_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 60\n",
    "batch_size = 512\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Train Loss:   2.5022 Valid Loss:   2.4359 Valid Accuracy: 0.133800 \n",
      "Epoch  2, CIFAR-10 Batch 1:  Train Loss:   2.1839 Valid Loss:   2.1234 Valid Accuracy: 0.217000 \n",
      "Epoch  3, CIFAR-10 Batch 1:  Train Loss:   1.9828 Valid Loss:   1.9220 Valid Accuracy: 0.283200 \n",
      "Epoch  4, CIFAR-10 Batch 1:  Train Loss:   1.8419 Valid Loss:   1.7897 Valid Accuracy: 0.333200 \n",
      "Epoch  5, CIFAR-10 Batch 1:  Train Loss:   1.7211 Valid Loss:   1.6827 Valid Accuracy: 0.389200 \n",
      "Epoch  6, CIFAR-10 Batch 1:  Train Loss:   1.6355 Valid Loss:   1.5904 Valid Accuracy: 0.414200 \n",
      "Epoch  7, CIFAR-10 Batch 1:  Train Loss:   1.5923 Valid Loss:   1.5484 Valid Accuracy: 0.435000 \n",
      "Epoch  8, CIFAR-10 Batch 1:  Train Loss:   1.5341 Valid Loss:   1.5137 Valid Accuracy: 0.436400 \n",
      "Epoch  9, CIFAR-10 Batch 1:  Train Loss:   1.4684 Valid Loss:   1.4672 Valid Accuracy: 0.458600 \n",
      "Epoch 10, CIFAR-10 Batch 1:  Train Loss:   1.4234 Valid Loss:   1.4244 Valid Accuracy: 0.468200 \n",
      "Epoch 11, CIFAR-10 Batch 1:  Train Loss:   1.3599 Valid Loss:   1.3914 Valid Accuracy: 0.489800 \n",
      "Epoch 12, CIFAR-10 Batch 1:  Train Loss:   1.3061 Valid Loss:   1.3619 Valid Accuracy: 0.509400 \n",
      "Epoch 13, CIFAR-10 Batch 1:  Train Loss:   1.2854 Valid Loss:   1.3557 Valid Accuracy: 0.507800 \n",
      "Epoch 14, CIFAR-10 Batch 1:  Train Loss:   1.2446 Valid Loss:   1.3367 Valid Accuracy: 0.514000 \n",
      "Epoch 15, CIFAR-10 Batch 1:  Train Loss:   1.2186 Valid Loss:   1.3187 Valid Accuracy: 0.522200 \n",
      "Epoch 16, CIFAR-10 Batch 1:  Train Loss:   1.1989 Valid Loss:   1.3121 Valid Accuracy: 0.520400 \n",
      "Epoch 17, CIFAR-10 Batch 1:  Train Loss:   1.1360 Valid Loss:   1.2864 Valid Accuracy: 0.528600 \n",
      "Epoch 18, CIFAR-10 Batch 1:  Train Loss:   1.0872 Valid Loss:   1.2672 Valid Accuracy: 0.541400 \n",
      "Epoch 19, CIFAR-10 Batch 1:  Train Loss:   1.0107 Valid Loss:   1.2405 Valid Accuracy: 0.556000 \n",
      "Epoch 20, CIFAR-10 Batch 1:  Train Loss:   0.9850 Valid Loss:   1.2454 Valid Accuracy: 0.554000 \n",
      "Epoch 21, CIFAR-10 Batch 1:  Train Loss:   0.9471 Valid Loss:   1.2191 Valid Accuracy: 0.557000 \n",
      "Epoch 22, CIFAR-10 Batch 1:  Train Loss:   0.8792 Valid Loss:   1.2021 Valid Accuracy: 0.564200 \n",
      "Epoch 23, CIFAR-10 Batch 1:  Train Loss:   0.8416 Valid Loss:   1.1906 Valid Accuracy: 0.576000 \n",
      "Epoch 24, CIFAR-10 Batch 1:  Train Loss:   0.8245 Valid Loss:   1.1985 Valid Accuracy: 0.571600 \n",
      "Epoch 25, CIFAR-10 Batch 1:  Train Loss:   0.8108 Valid Loss:   1.1959 Valid Accuracy: 0.572600 \n",
      "Epoch 26, CIFAR-10 Batch 1:  Train Loss:   0.7342 Valid Loss:   1.1763 Valid Accuracy: 0.581000 \n",
      "Epoch 27, CIFAR-10 Batch 1:  Train Loss:   0.6959 Valid Loss:   1.1842 Valid Accuracy: 0.576000 \n",
      "Epoch 28, CIFAR-10 Batch 1:  Train Loss:   0.6911 Valid Loss:   1.2015 Valid Accuracy: 0.577200 \n",
      "Epoch 29, CIFAR-10 Batch 1:  Train Loss:   0.6374 Valid Loss:   1.1703 Valid Accuracy: 0.587000 \n",
      "Epoch 30, CIFAR-10 Batch 1:  Train Loss:   0.6212 Valid Loss:   1.1916 Valid Accuracy: 0.585200 \n",
      "Epoch 31, CIFAR-10 Batch 1:  Train Loss:   0.5716 Valid Loss:   1.1837 Valid Accuracy: 0.586600 \n",
      "Epoch 32, CIFAR-10 Batch 1:  Train Loss:   0.5480 Valid Loss:   1.2226 Valid Accuracy: 0.577200 \n",
      "Epoch 33, CIFAR-10 Batch 1:  Train Loss:   0.4839 Valid Loss:   1.1710 Valid Accuracy: 0.592600 \n",
      "Epoch 34, CIFAR-10 Batch 1:  Train Loss:   0.4624 Valid Loss:   1.1778 Valid Accuracy: 0.592000 \n",
      "Epoch 35, CIFAR-10 Batch 1:  Train Loss:   0.4223 Valid Loss:   1.1462 Valid Accuracy: 0.605200 \n",
      "Epoch 36, CIFAR-10 Batch 1:  Train Loss:   0.4134 Valid Loss:   1.1854 Valid Accuracy: 0.595000 \n",
      "Epoch 37, CIFAR-10 Batch 1:  Train Loss:   0.3823 Valid Loss:   1.1838 Valid Accuracy: 0.604600 \n",
      "Epoch 38, CIFAR-10 Batch 1:  Train Loss:   0.3406 Valid Loss:   1.1777 Valid Accuracy: 0.606800 \n",
      "Epoch 39, CIFAR-10 Batch 1:  Train Loss:   0.3377 Valid Loss:   1.2421 Valid Accuracy: 0.593400 \n",
      "Epoch 40, CIFAR-10 Batch 1:  Train Loss:   0.3407 Valid Loss:   1.2877 Valid Accuracy: 0.586600 \n",
      "Epoch 41, CIFAR-10 Batch 1:  Train Loss:   0.3203 Valid Loss:   1.2858 Valid Accuracy: 0.583000 \n",
      "Epoch 42, CIFAR-10 Batch 1:  Train Loss:   0.3050 Valid Loss:   1.2286 Valid Accuracy: 0.598400 \n",
      "Epoch 43, CIFAR-10 Batch 1:  Train Loss:   0.2508 Valid Loss:   1.1915 Valid Accuracy: 0.613600 \n",
      "Epoch 44, CIFAR-10 Batch 1:  Train Loss:   0.2407 Valid Loss:   1.2541 Valid Accuracy: 0.598200 \n",
      "Epoch 45, CIFAR-10 Batch 1:  Train Loss:   0.2080 Valid Loss:   1.2408 Valid Accuracy: 0.607800 \n",
      "Epoch 46, CIFAR-10 Batch 1:  Train Loss:   0.1911 Valid Loss:   1.2644 Valid Accuracy: 0.607200 \n",
      "Epoch 47, CIFAR-10 Batch 1:  Train Loss:   0.1902 Valid Loss:   1.2892 Valid Accuracy: 0.597600 \n",
      "Epoch 48, CIFAR-10 Batch 1:  Train Loss:   0.1741 Valid Loss:   1.3491 Valid Accuracy: 0.591400 \n",
      "Epoch 49, CIFAR-10 Batch 1:  Train Loss:   0.1857 Valid Loss:   1.3923 Valid Accuracy: 0.588400 \n",
      "Epoch 50, CIFAR-10 Batch 1:  Train Loss:   0.1366 Valid Loss:   1.3103 Valid Accuracy: 0.599000 \n",
      "Epoch 51, CIFAR-10 Batch 1:  Train Loss:   0.1299 Valid Loss:   1.3847 Valid Accuracy: 0.600800 \n",
      "Epoch 52, CIFAR-10 Batch 1:  Train Loss:   0.1490 Valid Loss:   1.4416 Valid Accuracy: 0.586600 \n",
      "Epoch 53, CIFAR-10 Batch 1:  Train Loss:   0.1522 Valid Loss:   1.4164 Valid Accuracy: 0.592400 \n",
      "Epoch 54, CIFAR-10 Batch 1:  Train Loss:   0.1384 Valid Loss:   1.3159 Valid Accuracy: 0.603200 \n",
      "Epoch 55, CIFAR-10 Batch 1:  Train Loss:   0.1081 Valid Loss:   1.3019 Valid Accuracy: 0.612000 \n",
      "Epoch 56, CIFAR-10 Batch 1:  Train Loss:   0.1040 Valid Loss:   1.2723 Valid Accuracy: 0.619600 \n",
      "Epoch 57, CIFAR-10 Batch 1:  Train Loss:   0.1116 Valid Loss:   1.3717 Valid Accuracy: 0.599000 \n",
      "Epoch 58, CIFAR-10 Batch 1:  Train Loss:   0.0969 Valid Loss:   1.3553 Valid Accuracy: 0.601600 \n",
      "Epoch 59, CIFAR-10 Batch 1:  Train Loss:   0.1056 Valid Loss:   1.3804 Valid Accuracy: 0.598000 \n",
      "Epoch 60, CIFAR-10 Batch 1:  Train Loss:   0.0695 Valid Loss:   1.3705 Valid Accuracy: 0.608400 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Train Loss:   2.2910 Valid Loss:   2.2560 Valid Accuracy: 0.206400 \n",
      "Epoch  1, CIFAR-10 Batch 2:  Train Loss:   2.1662 Valid Loss:   2.1474 Valid Accuracy: 0.217200 \n",
      "Epoch  1, CIFAR-10 Batch 3:  Train Loss:   1.8864 Valid Loss:   1.8853 Valid Accuracy: 0.303200 \n",
      "Epoch  1, CIFAR-10 Batch 4:  Train Loss:   1.7155 Valid Loss:   1.7524 Valid Accuracy: 0.359800 \n",
      "Epoch  1, CIFAR-10 Batch 5:  Train Loss:   1.6372 Valid Loss:   1.6484 Valid Accuracy: 0.393200 \n",
      "Epoch  2, CIFAR-10 Batch 1:  Train Loss:   1.6834 Valid Loss:   1.5542 Valid Accuracy: 0.427800 \n",
      "Epoch  2, CIFAR-10 Batch 2:  Train Loss:   1.5780 Valid Loss:   1.5617 Valid Accuracy: 0.421600 \n",
      "Epoch  2, CIFAR-10 Batch 3:  Train Loss:   1.3753 Valid Loss:   1.4715 Valid Accuracy: 0.459000 \n",
      "Epoch  2, CIFAR-10 Batch 4:  Train Loss:   1.3991 Valid Loss:   1.4448 Valid Accuracy: 0.474400 \n",
      "Epoch  2, CIFAR-10 Batch 5:  Train Loss:   1.3607 Valid Loss:   1.4234 Valid Accuracy: 0.469200 \n",
      "Epoch  3, CIFAR-10 Batch 1:  Train Loss:   1.4638 Valid Loss:   1.3689 Valid Accuracy: 0.504800 \n",
      "Epoch  3, CIFAR-10 Batch 2:  Train Loss:   1.3608 Valid Loss:   1.3644 Valid Accuracy: 0.498000 \n",
      "Epoch  3, CIFAR-10 Batch 3:  Train Loss:   1.1874 Valid Loss:   1.3282 Valid Accuracy: 0.508200 \n",
      "Epoch  3, CIFAR-10 Batch 4:  Train Loss:   1.2250 Valid Loss:   1.3101 Valid Accuracy: 0.526600 \n",
      "Epoch  3, CIFAR-10 Batch 5:  Train Loss:   1.2145 Valid Loss:   1.3046 Valid Accuracy: 0.518600 \n",
      "Epoch  4, CIFAR-10 Batch 1:  Train Loss:   1.3279 Valid Loss:   1.2970 Valid Accuracy: 0.526400 \n",
      "Epoch  4, CIFAR-10 Batch 2:  Train Loss:   1.2506 Valid Loss:   1.2885 Valid Accuracy: 0.532200 \n",
      "Epoch  4, CIFAR-10 Batch 3:  Train Loss:   1.0860 Valid Loss:   1.2467 Valid Accuracy: 0.550200 \n",
      "Epoch  4, CIFAR-10 Batch 4:  Train Loss:   1.1220 Valid Loss:   1.2363 Valid Accuracy: 0.555400 \n",
      "Epoch  4, CIFAR-10 Batch 5:  Train Loss:   1.1118 Valid Loss:   1.2282 Valid Accuracy: 0.546400 \n",
      "Epoch  5, CIFAR-10 Batch 1:  Train Loss:   1.2255 Valid Loss:   1.2208 Valid Accuracy: 0.556200 \n",
      "Epoch  5, CIFAR-10 Batch 2:  Train Loss:   1.1572 Valid Loss:   1.2368 Valid Accuracy: 0.548800 \n",
      "Epoch  5, CIFAR-10 Batch 3:  Train Loss:   1.0090 Valid Loss:   1.1941 Valid Accuracy: 0.571200 \n",
      "Epoch  5, CIFAR-10 Batch 4:  Train Loss:   1.0339 Valid Loss:   1.1908 Valid Accuracy: 0.568200 \n",
      "Epoch  5, CIFAR-10 Batch 5:  Train Loss:   1.0428 Valid Loss:   1.1781 Valid Accuracy: 0.569000 \n",
      "Epoch  6, CIFAR-10 Batch 1:  Train Loss:   1.1522 Valid Loss:   1.1506 Valid Accuracy: 0.579600 \n",
      "Epoch  6, CIFAR-10 Batch 2:  Train Loss:   1.0879 Valid Loss:   1.1771 Valid Accuracy: 0.566600 \n",
      "Epoch  6, CIFAR-10 Batch 3:  Train Loss:   0.9295 Valid Loss:   1.1494 Valid Accuracy: 0.588800 \n",
      "Epoch  6, CIFAR-10 Batch 4:  Train Loss:   0.9401 Valid Loss:   1.1422 Valid Accuracy: 0.590000 \n",
      "Epoch  6, CIFAR-10 Batch 5:  Train Loss:   0.9683 Valid Loss:   1.1146 Valid Accuracy: 0.596800 \n",
      "Epoch  7, CIFAR-10 Batch 1:  Train Loss:   1.0624 Valid Loss:   1.0875 Valid Accuracy: 0.615600 \n",
      "Epoch  7, CIFAR-10 Batch 2:  Train Loss:   0.9898 Valid Loss:   1.1086 Valid Accuracy: 0.597600 \n",
      "Epoch  7, CIFAR-10 Batch 3:  Train Loss:   0.8837 Valid Loss:   1.1211 Valid Accuracy: 0.600800 \n",
      "Epoch  7, CIFAR-10 Batch 4:  Train Loss:   0.8435 Valid Loss:   1.0873 Valid Accuracy: 0.615800 \n",
      "Epoch  7, CIFAR-10 Batch 5:  Train Loss:   0.8921 Valid Loss:   1.0724 Valid Accuracy: 0.615600 \n",
      "Epoch  8, CIFAR-10 Batch 1:  Train Loss:   0.9907 Valid Loss:   1.0703 Valid Accuracy: 0.608600 \n",
      "Epoch  8, CIFAR-10 Batch 2:  Train Loss:   0.9315 Valid Loss:   1.0737 Valid Accuracy: 0.613000 \n",
      "Epoch  8, CIFAR-10 Batch 3:  Train Loss:   0.8062 Valid Loss:   1.0745 Valid Accuracy: 0.619600 \n",
      "Epoch  8, CIFAR-10 Batch 4:  Train Loss:   0.7876 Valid Loss:   1.0546 Valid Accuracy: 0.621000 \n",
      "Epoch  8, CIFAR-10 Batch 5:  Train Loss:   0.8343 Valid Loss:   1.0288 Valid Accuracy: 0.627000 \n",
      "Epoch  9, CIFAR-10 Batch 1:  Train Loss:   0.9218 Valid Loss:   1.0196 Valid Accuracy: 0.627600 \n",
      "Epoch  9, CIFAR-10 Batch 2:  Train Loss:   0.8637 Valid Loss:   1.0250 Valid Accuracy: 0.633400 \n",
      "Epoch  9, CIFAR-10 Batch 3:  Train Loss:   0.7396 Valid Loss:   1.0320 Valid Accuracy: 0.628800 \n",
      "Epoch  9, CIFAR-10 Batch 4:  Train Loss:   0.7115 Valid Loss:   1.0090 Valid Accuracy: 0.643000 \n",
      "Epoch  9, CIFAR-10 Batch 5:  Train Loss:   0.7651 Valid Loss:   0.9937 Valid Accuracy: 0.645800 \n",
      "Epoch 10, CIFAR-10 Batch 1:  Train Loss:   0.8799 Valid Loss:   1.0175 Valid Accuracy: 0.631200 \n",
      "Epoch 10, CIFAR-10 Batch 2:  Train Loss:   0.8024 Valid Loss:   1.0165 Valid Accuracy: 0.635000 \n",
      "Epoch 10, CIFAR-10 Batch 3:  Train Loss:   0.7049 Valid Loss:   1.0030 Valid Accuracy: 0.638200 \n",
      "Epoch 10, CIFAR-10 Batch 4:  Train Loss:   0.6897 Valid Loss:   0.9915 Valid Accuracy: 0.646000 \n",
      "Epoch 10, CIFAR-10 Batch 5:  Train Loss:   0.7111 Valid Loss:   0.9691 Valid Accuracy: 0.656000 \n",
      "Epoch 11, CIFAR-10 Batch 1:  Train Loss:   0.8037 Valid Loss:   0.9648 Valid Accuracy: 0.653000 \n",
      "Epoch 11, CIFAR-10 Batch 2:  Train Loss:   0.7616 Valid Loss:   0.9832 Valid Accuracy: 0.643000 \n",
      "Epoch 11, CIFAR-10 Batch 3:  Train Loss:   0.6575 Valid Loss:   0.9918 Valid Accuracy: 0.649200 \n",
      "Epoch 11, CIFAR-10 Batch 4:  Train Loss:   0.6264 Valid Loss:   0.9615 Valid Accuracy: 0.655400 \n",
      "Epoch 11, CIFAR-10 Batch 5:  Train Loss:   0.6763 Valid Loss:   0.9554 Valid Accuracy: 0.656600 \n",
      "Epoch 12, CIFAR-10 Batch 1:  Train Loss:   0.7463 Valid Loss:   0.9519 Valid Accuracy: 0.658000 \n",
      "Epoch 12, CIFAR-10 Batch 2:  Train Loss:   0.7089 Valid Loss:   0.9669 Valid Accuracy: 0.652600 \n",
      "Epoch 12, CIFAR-10 Batch 3:  Train Loss:   0.5799 Valid Loss:   0.9404 Valid Accuracy: 0.667800 \n",
      "Epoch 12, CIFAR-10 Batch 4:  Train Loss:   0.5892 Valid Loss:   0.9579 Valid Accuracy: 0.662800 \n",
      "Epoch 12, CIFAR-10 Batch 5:  Train Loss:   0.6630 Valid Loss:   0.9563 Valid Accuracy: 0.659600 \n",
      "Epoch 13, CIFAR-10 Batch 1:  Train Loss:   0.6965 Valid Loss:   0.9275 Valid Accuracy: 0.671000 \n",
      "Epoch 13, CIFAR-10 Batch 2:  Train Loss:   0.6302 Valid Loss:   0.9221 Valid Accuracy: 0.669400 \n",
      "Epoch 13, CIFAR-10 Batch 3:  Train Loss:   0.6110 Valid Loss:   0.9691 Valid Accuracy: 0.663200 \n",
      "Epoch 13, CIFAR-10 Batch 4:  Train Loss:   0.5532 Valid Loss:   0.9263 Valid Accuracy: 0.671200 \n",
      "Epoch 13, CIFAR-10 Batch 5:  Train Loss:   0.6174 Valid Loss:   0.9383 Valid Accuracy: 0.665800 \n",
      "Epoch 14, CIFAR-10 Batch 1:  Train Loss:   0.6613 Valid Loss:   0.9203 Valid Accuracy: 0.670600 \n",
      "Epoch 14, CIFAR-10 Batch 2:  Train Loss:   0.6176 Valid Loss:   0.9288 Valid Accuracy: 0.667200 \n",
      "Epoch 14, CIFAR-10 Batch 3:  Train Loss:   0.5753 Valid Loss:   0.9775 Valid Accuracy: 0.652600 \n",
      "Epoch 14, CIFAR-10 Batch 4:  Train Loss:   0.5340 Valid Loss:   0.9288 Valid Accuracy: 0.672600 \n",
      "Epoch 14, CIFAR-10 Batch 5:  Train Loss:   0.5553 Valid Loss:   0.8934 Valid Accuracy: 0.684400 \n",
      "Epoch 15, CIFAR-10 Batch 1:  Train Loss:   0.6222 Valid Loss:   0.9049 Valid Accuracy: 0.681600 \n",
      "Epoch 15, CIFAR-10 Batch 2:  Train Loss:   0.5614 Valid Loss:   0.9048 Valid Accuracy: 0.676800 \n",
      "Epoch 15, CIFAR-10 Batch 3:  Train Loss:   0.5003 Valid Loss:   0.9213 Valid Accuracy: 0.677600 \n",
      "Epoch 15, CIFAR-10 Batch 4:  Train Loss:   0.4898 Valid Loss:   0.8947 Valid Accuracy: 0.680800 \n",
      "Epoch 15, CIFAR-10 Batch 5:  Train Loss:   0.5453 Valid Loss:   0.9018 Valid Accuracy: 0.676200 \n",
      "Epoch 16, CIFAR-10 Batch 1:  Train Loss:   0.5916 Valid Loss:   0.8921 Valid Accuracy: 0.686800 \n",
      "Epoch 16, CIFAR-10 Batch 2:  Train Loss:   0.6047 Valid Loss:   1.0219 Valid Accuracy: 0.639600 \n",
      "Epoch 16, CIFAR-10 Batch 3:  Train Loss:   0.4735 Valid Loss:   0.8952 Valid Accuracy: 0.680400 \n",
      "Epoch 16, CIFAR-10 Batch 4:  Train Loss:   0.4899 Valid Loss:   0.8945 Valid Accuracy: 0.681000 \n",
      "Epoch 16, CIFAR-10 Batch 5:  Train Loss:   0.5248 Valid Loss:   0.8904 Valid Accuracy: 0.684800 \n",
      "Epoch 17, CIFAR-10 Batch 1:  Train Loss:   0.5638 Valid Loss:   0.8910 Valid Accuracy: 0.688400 \n",
      "Epoch 17, CIFAR-10 Batch 2:  Train Loss:   0.5027 Valid Loss:   0.9049 Valid Accuracy: 0.680000 \n",
      "Epoch 17, CIFAR-10 Batch 3:  Train Loss:   0.4282 Valid Loss:   0.9006 Valid Accuracy: 0.686800 \n",
      "Epoch 17, CIFAR-10 Batch 4:  Train Loss:   0.4610 Valid Loss:   0.9008 Valid Accuracy: 0.684600 \n",
      "Epoch 17, CIFAR-10 Batch 5:  Train Loss:   0.4739 Valid Loss:   0.8765 Valid Accuracy: 0.691000 \n",
      "Epoch 18, CIFAR-10 Batch 1:  Train Loss:   0.5040 Valid Loss:   0.8506 Valid Accuracy: 0.703800 \n",
      "Epoch 18, CIFAR-10 Batch 2:  Train Loss:   0.4734 Valid Loss:   0.9228 Valid Accuracy: 0.673800 \n",
      "Epoch 18, CIFAR-10 Batch 3:  Train Loss:   0.3927 Valid Loss:   0.8701 Valid Accuracy: 0.693800 \n",
      "Epoch 18, CIFAR-10 Batch 4:  Train Loss:   0.4380 Valid Loss:   0.8974 Valid Accuracy: 0.685400 \n",
      "Epoch 18, CIFAR-10 Batch 5:  Train Loss:   0.4463 Valid Loss:   0.8774 Valid Accuracy: 0.690600 \n",
      "Epoch 19, CIFAR-10 Batch 1:  Train Loss:   0.4870 Valid Loss:   0.8649 Valid Accuracy: 0.704800 \n",
      "Epoch 19, CIFAR-10 Batch 2:  Train Loss:   0.4404 Valid Loss:   0.9118 Valid Accuracy: 0.685000 \n",
      "Epoch 19, CIFAR-10 Batch 3:  Train Loss:   0.3430 Valid Loss:   0.8637 Valid Accuracy: 0.696800 \n",
      "Epoch 19, CIFAR-10 Batch 4:  Train Loss:   0.4174 Valid Loss:   0.9199 Valid Accuracy: 0.684800 \n",
      "Epoch 19, CIFAR-10 Batch 5:  Train Loss:   0.4162 Valid Loss:   0.8820 Valid Accuracy: 0.692800 \n",
      "Epoch 20, CIFAR-10 Batch 1:  Train Loss:   0.4589 Valid Loss:   0.8545 Valid Accuracy: 0.704200 \n",
      "Epoch 20, CIFAR-10 Batch 2:  Train Loss:   0.3933 Valid Loss:   0.8789 Valid Accuracy: 0.696200 \n",
      "Epoch 20, CIFAR-10 Batch 3:  Train Loss:   0.3204 Valid Loss:   0.8481 Valid Accuracy: 0.702000 \n",
      "Epoch 20, CIFAR-10 Batch 4:  Train Loss:   0.3727 Valid Loss:   0.8970 Valid Accuracy: 0.682200 \n",
      "Epoch 20, CIFAR-10 Batch 5:  Train Loss:   0.3990 Valid Loss:   0.8568 Valid Accuracy: 0.699400 \n",
      "Epoch 21, CIFAR-10 Batch 1:  Train Loss:   0.4067 Valid Loss:   0.8641 Valid Accuracy: 0.696600 \n",
      "Epoch 21, CIFAR-10 Batch 2:  Train Loss:   0.3860 Valid Loss:   0.8850 Valid Accuracy: 0.691600 \n",
      "Epoch 21, CIFAR-10 Batch 3:  Train Loss:   0.3391 Valid Loss:   0.8967 Valid Accuracy: 0.687800 \n",
      "Epoch 21, CIFAR-10 Batch 4:  Train Loss:   0.3228 Valid Loss:   0.8377 Valid Accuracy: 0.706600 \n",
      "Epoch 21, CIFAR-10 Batch 5:  Train Loss:   0.3402 Valid Loss:   0.8765 Valid Accuracy: 0.689200 \n",
      "Epoch 22, CIFAR-10 Batch 1:  Train Loss:   0.4340 Valid Loss:   0.8816 Valid Accuracy: 0.688600 \n",
      "Epoch 22, CIFAR-10 Batch 2:  Train Loss:   0.3705 Valid Loss:   0.8723 Valid Accuracy: 0.693200 \n",
      "Epoch 22, CIFAR-10 Batch 3:  Train Loss:   0.2992 Valid Loss:   0.9046 Valid Accuracy: 0.688600 \n",
      "Epoch 22, CIFAR-10 Batch 4:  Train Loss:   0.3717 Valid Loss:   0.8835 Valid Accuracy: 0.686200 \n",
      "Epoch 22, CIFAR-10 Batch 5:  Train Loss:   0.3347 Valid Loss:   0.8569 Valid Accuracy: 0.700800 \n",
      "Epoch 23, CIFAR-10 Batch 1:  Train Loss:   0.4094 Valid Loss:   0.8867 Valid Accuracy: 0.692200 \n",
      "Epoch 23, CIFAR-10 Batch 2:  Train Loss:   0.3358 Valid Loss:   0.8395 Valid Accuracy: 0.704000 \n",
      "Epoch 23, CIFAR-10 Batch 3:  Train Loss:   0.2685 Valid Loss:   0.8761 Valid Accuracy: 0.704800 \n",
      "Epoch 23, CIFAR-10 Batch 4:  Train Loss:   0.3170 Valid Loss:   0.8595 Valid Accuracy: 0.701000 \n",
      "Epoch 23, CIFAR-10 Batch 5:  Train Loss:   0.3040 Valid Loss:   0.8652 Valid Accuracy: 0.697200 \n",
      "Epoch 24, CIFAR-10 Batch 1:  Train Loss:   0.3280 Valid Loss:   0.8600 Valid Accuracy: 0.701200 \n",
      "Epoch 24, CIFAR-10 Batch 2:  Train Loss:   0.3056 Valid Loss:   0.8129 Valid Accuracy: 0.718000 \n",
      "Epoch 24, CIFAR-10 Batch 3:  Train Loss:   0.2490 Valid Loss:   0.8722 Valid Accuracy: 0.704800 \n",
      "Epoch 24, CIFAR-10 Batch 4:  Train Loss:   0.2766 Valid Loss:   0.8604 Valid Accuracy: 0.702200 \n",
      "Epoch 24, CIFAR-10 Batch 5:  Train Loss:   0.2838 Valid Loss:   0.8387 Valid Accuracy: 0.704400 \n",
      "Epoch 25, CIFAR-10 Batch 1:  Train Loss:   0.2920 Valid Loss:   0.8413 Valid Accuracy: 0.704000 \n",
      "Epoch 25, CIFAR-10 Batch 2:  Train Loss:   0.2976 Valid Loss:   0.8590 Valid Accuracy: 0.697000 \n",
      "Epoch 25, CIFAR-10 Batch 3:  Train Loss:   0.2248 Valid Loss:   0.8910 Valid Accuracy: 0.697800 \n",
      "Epoch 25, CIFAR-10 Batch 4:  Train Loss:   0.2817 Valid Loss:   0.8451 Valid Accuracy: 0.706600 \n",
      "Epoch 25, CIFAR-10 Batch 5:  Train Loss:   0.2601 Valid Loss:   0.8352 Valid Accuracy: 0.704400 \n",
      "Epoch 26, CIFAR-10 Batch 1:  Train Loss:   0.2931 Valid Loss:   0.8574 Valid Accuracy: 0.697600 \n",
      "Epoch 26, CIFAR-10 Batch 2:  Train Loss:   0.2627 Valid Loss:   0.8471 Valid Accuracy: 0.707200 \n",
      "Epoch 26, CIFAR-10 Batch 3:  Train Loss:   0.2120 Valid Loss:   0.8526 Valid Accuracy: 0.714000 \n",
      "Epoch 26, CIFAR-10 Batch 4:  Train Loss:   0.2931 Valid Loss:   0.9042 Valid Accuracy: 0.689200 \n",
      "Epoch 26, CIFAR-10 Batch 5:  Train Loss:   0.2277 Valid Loss:   0.8360 Valid Accuracy: 0.709800 \n",
      "Epoch 27, CIFAR-10 Batch 1:  Train Loss:   0.2729 Valid Loss:   0.8629 Valid Accuracy: 0.701200 \n",
      "Epoch 27, CIFAR-10 Batch 2:  Train Loss:   0.2389 Valid Loss:   0.8337 Valid Accuracy: 0.713200 \n",
      "Epoch 27, CIFAR-10 Batch 3:  Train Loss:   0.2060 Valid Loss:   0.9015 Valid Accuracy: 0.693000 \n",
      "Epoch 27, CIFAR-10 Batch 4:  Train Loss:   0.2725 Valid Loss:   0.8992 Valid Accuracy: 0.694400 \n",
      "Epoch 27, CIFAR-10 Batch 5:  Train Loss:   0.2635 Valid Loss:   0.8768 Valid Accuracy: 0.697000 \n",
      "Epoch 28, CIFAR-10 Batch 1:  Train Loss:   0.2482 Valid Loss:   0.8576 Valid Accuracy: 0.707600 \n",
      "Epoch 28, CIFAR-10 Batch 2:  Train Loss:   0.2693 Valid Loss:   0.9100 Valid Accuracy: 0.682800 \n",
      "Epoch 28, CIFAR-10 Batch 3:  Train Loss:   0.2180 Valid Loss:   0.9366 Valid Accuracy: 0.685800 \n",
      "Epoch 28, CIFAR-10 Batch 4:  Train Loss:   0.2387 Valid Loss:   0.8710 Valid Accuracy: 0.695600 \n",
      "Epoch 28, CIFAR-10 Batch 5:  Train Loss:   0.2894 Valid Loss:   0.9315 Valid Accuracy: 0.684800 \n",
      "Epoch 29, CIFAR-10 Batch 1:  Train Loss:   0.2585 Valid Loss:   0.8725 Valid Accuracy: 0.702000 \n",
      "Epoch 29, CIFAR-10 Batch 2:  Train Loss:   0.2414 Valid Loss:   0.8637 Valid Accuracy: 0.699800 \n",
      "Epoch 29, CIFAR-10 Batch 3:  Train Loss:   0.1861 Valid Loss:   0.8476 Valid Accuracy: 0.714400 \n",
      "Epoch 29, CIFAR-10 Batch 4:  Train Loss:   0.2123 Valid Loss:   0.8574 Valid Accuracy: 0.701000 \n",
      "Epoch 29, CIFAR-10 Batch 5:  Train Loss:   0.2253 Valid Loss:   0.8559 Valid Accuracy: 0.704600 \n",
      "Epoch 30, CIFAR-10 Batch 1:  Train Loss:   0.2172 Valid Loss:   0.8711 Valid Accuracy: 0.705800 \n",
      "Epoch 30, CIFAR-10 Batch 2:  Train Loss:   0.2211 Valid Loss:   0.8664 Valid Accuracy: 0.703400 \n",
      "Epoch 30, CIFAR-10 Batch 3:  Train Loss:   0.1864 Valid Loss:   0.9069 Valid Accuracy: 0.696200 \n",
      "Epoch 30, CIFAR-10 Batch 4:  Train Loss:   0.1886 Valid Loss:   0.8215 Valid Accuracy: 0.719400 \n",
      "Epoch 30, CIFAR-10 Batch 5:  Train Loss:   0.2129 Valid Loss:   0.8674 Valid Accuracy: 0.701400 \n",
      "Epoch 31, CIFAR-10 Batch 1:  Train Loss:   0.1855 Valid Loss:   0.8496 Valid Accuracy: 0.713800 \n",
      "Epoch 31, CIFAR-10 Batch 2:  Train Loss:   0.1924 Valid Loss:   0.8659 Valid Accuracy: 0.708200 \n",
      "Epoch 31, CIFAR-10 Batch 3:  Train Loss:   0.1883 Valid Loss:   0.9129 Valid Accuracy: 0.701000 \n",
      "Epoch 31, CIFAR-10 Batch 4:  Train Loss:   0.1906 Valid Loss:   0.8460 Valid Accuracy: 0.712800 \n",
      "Epoch 31, CIFAR-10 Batch 5:  Train Loss:   0.1736 Valid Loss:   0.8590 Valid Accuracy: 0.708200 \n",
      "Epoch 32, CIFAR-10 Batch 1:  Train Loss:   0.1922 Valid Loss:   0.8997 Valid Accuracy: 0.694800 \n",
      "Epoch 32, CIFAR-10 Batch 2:  Train Loss:   0.1515 Valid Loss:   0.8445 Valid Accuracy: 0.713200 \n",
      "Epoch 32, CIFAR-10 Batch 3:  Train Loss:   0.1466 Valid Loss:   0.9001 Valid Accuracy: 0.697800 \n",
      "Epoch 32, CIFAR-10 Batch 4:  Train Loss:   0.1722 Valid Loss:   0.8469 Valid Accuracy: 0.708200 \n",
      "Epoch 32, CIFAR-10 Batch 5:  Train Loss:   0.1705 Valid Loss:   0.8637 Valid Accuracy: 0.702400 \n",
      "Epoch 33, CIFAR-10 Batch 1:  Train Loss:   0.1803 Valid Loss:   0.9390 Valid Accuracy: 0.696000 \n",
      "Epoch 33, CIFAR-10 Batch 2:  Train Loss:   0.1545 Valid Loss:   0.9211 Valid Accuracy: 0.697800 \n",
      "Epoch 33, CIFAR-10 Batch 3:  Train Loss:   0.1419 Valid Loss:   0.8973 Valid Accuracy: 0.710200 \n",
      "Epoch 33, CIFAR-10 Batch 4:  Train Loss:   0.1992 Valid Loss:   0.8937 Valid Accuracy: 0.696400 \n",
      "Epoch 33, CIFAR-10 Batch 5:  Train Loss:   0.2057 Valid Loss:   0.9271 Valid Accuracy: 0.683000 \n",
      "Epoch 34, CIFAR-10 Batch 1:  Train Loss:   0.1554 Valid Loss:   0.8918 Valid Accuracy: 0.714400 \n",
      "Epoch 34, CIFAR-10 Batch 2:  Train Loss:   0.1199 Valid Loss:   0.8427 Valid Accuracy: 0.719200 \n",
      "Epoch 34, CIFAR-10 Batch 3:  Train Loss:   0.1164 Valid Loss:   0.8833 Valid Accuracy: 0.712200 \n",
      "Epoch 34, CIFAR-10 Batch 4:  Train Loss:   0.1406 Valid Loss:   0.8926 Valid Accuracy: 0.703000 \n",
      "Epoch 34, CIFAR-10 Batch 5:  Train Loss:   0.1613 Valid Loss:   0.9171 Valid Accuracy: 0.690400 \n",
      "Epoch 35, CIFAR-10 Batch 1:  Train Loss:   0.1670 Valid Loss:   0.9421 Valid Accuracy: 0.693800 \n",
      "Epoch 35, CIFAR-10 Batch 2:  Train Loss:   0.1409 Valid Loss:   0.8703 Valid Accuracy: 0.714000 \n",
      "Epoch 35, CIFAR-10 Batch 3:  Train Loss:   0.1169 Valid Loss:   0.8973 Valid Accuracy: 0.704600 \n",
      "Epoch 35, CIFAR-10 Batch 4:  Train Loss:   0.1628 Valid Loss:   0.9623 Valid Accuracy: 0.679600 \n",
      "Epoch 35, CIFAR-10 Batch 5:  Train Loss:   0.1545 Valid Loss:   0.8907 Valid Accuracy: 0.702000 \n",
      "Epoch 36, CIFAR-10 Batch 1:  Train Loss:   0.1270 Valid Loss:   0.8969 Valid Accuracy: 0.711400 \n",
      "Epoch 36, CIFAR-10 Batch 2:  Train Loss:   0.1415 Valid Loss:   0.8580 Valid Accuracy: 0.712800 \n",
      "Epoch 36, CIFAR-10 Batch 3:  Train Loss:   0.1122 Valid Loss:   0.9166 Valid Accuracy: 0.695400 \n",
      "Epoch 36, CIFAR-10 Batch 4:  Train Loss:   0.1537 Valid Loss:   0.9360 Valid Accuracy: 0.696200 \n",
      "Epoch 36, CIFAR-10 Batch 5:  Train Loss:   0.1400 Valid Loss:   0.9065 Valid Accuracy: 0.694600 \n",
      "Epoch 37, CIFAR-10 Batch 1:  Train Loss:   0.1250 Valid Loss:   0.8914 Valid Accuracy: 0.704800 \n",
      "Epoch 37, CIFAR-10 Batch 2:  Train Loss:   0.1305 Valid Loss:   0.8841 Valid Accuracy: 0.706800 \n",
      "Epoch 37, CIFAR-10 Batch 3:  Train Loss:   0.1035 Valid Loss:   0.8932 Valid Accuracy: 0.712800 \n",
      "Epoch 37, CIFAR-10 Batch 4:  Train Loss:   0.1586 Valid Loss:   0.9528 Valid Accuracy: 0.687000 \n",
      "Epoch 37, CIFAR-10 Batch 5:  Train Loss:   0.1315 Valid Loss:   0.9088 Valid Accuracy: 0.695600 \n",
      "Epoch 38, CIFAR-10 Batch 1:  Train Loss:   0.1137 Valid Loss:   0.8616 Valid Accuracy: 0.717600 \n",
      "Epoch 38, CIFAR-10 Batch 2:  Train Loss:   0.1151 Valid Loss:   0.8627 Valid Accuracy: 0.712800 \n",
      "Epoch 38, CIFAR-10 Batch 3:  Train Loss:   0.0921 Valid Loss:   0.8952 Valid Accuracy: 0.711400 \n",
      "Epoch 38, CIFAR-10 Batch 4:  Train Loss:   0.1011 Valid Loss:   0.9004 Valid Accuracy: 0.706600 \n",
      "Epoch 38, CIFAR-10 Batch 5:  Train Loss:   0.1071 Valid Loss:   0.8695 Valid Accuracy: 0.715800 \n",
      "Epoch 39, CIFAR-10 Batch 1:  Train Loss:   0.1041 Valid Loss:   0.8642 Valid Accuracy: 0.721000 \n",
      "Epoch 39, CIFAR-10 Batch 2:  Train Loss:   0.0934 Valid Loss:   0.8736 Valid Accuracy: 0.718400 \n",
      "Epoch 39, CIFAR-10 Batch 3:  Train Loss:   0.0859 Valid Loss:   0.8999 Valid Accuracy: 0.715000 \n",
      "Epoch 39, CIFAR-10 Batch 4:  Train Loss:   0.0862 Valid Loss:   0.8923 Valid Accuracy: 0.711400 \n",
      "Epoch 39, CIFAR-10 Batch 5:  Train Loss:   0.0993 Valid Loss:   0.8678 Valid Accuracy: 0.713600 \n",
      "Epoch 40, CIFAR-10 Batch 1:  Train Loss:   0.0944 Valid Loss:   0.8757 Valid Accuracy: 0.720800 \n",
      "Epoch 40, CIFAR-10 Batch 2:  Train Loss:   0.1120 Valid Loss:   0.8837 Valid Accuracy: 0.707000 \n",
      "Epoch 40, CIFAR-10 Batch 3:  Train Loss:   0.0917 Valid Loss:   0.8820 Valid Accuracy: 0.721200 \n",
      "Epoch 40, CIFAR-10 Batch 4:  Train Loss:   0.0927 Valid Loss:   0.8917 Valid Accuracy: 0.707000 \n",
      "Epoch 40, CIFAR-10 Batch 5:  Train Loss:   0.1076 Valid Loss:   0.9215 Valid Accuracy: 0.701200 \n",
      "Epoch 41, CIFAR-10 Batch 1:  Train Loss:   0.0982 Valid Loss:   0.8870 Valid Accuracy: 0.712200 \n",
      "Epoch 41, CIFAR-10 Batch 2:  Train Loss:   0.0991 Valid Loss:   0.8618 Valid Accuracy: 0.711600 \n",
      "Epoch 41, CIFAR-10 Batch 3:  Train Loss:   0.0938 Valid Loss:   0.9481 Valid Accuracy: 0.704600 \n",
      "Epoch 41, CIFAR-10 Batch 4:  Train Loss:   0.0823 Valid Loss:   0.9132 Valid Accuracy: 0.702800 \n",
      "Epoch 41, CIFAR-10 Batch 5:  Train Loss:   0.0957 Valid Loss:   0.9218 Valid Accuracy: 0.705400 \n",
      "Epoch 42, CIFAR-10 Batch 1:  Train Loss:   0.0688 Valid Loss:   0.9103 Valid Accuracy: 0.712000 \n",
      "Epoch 42, CIFAR-10 Batch 2:  Train Loss:   0.0991 Valid Loss:   0.8788 Valid Accuracy: 0.712000 \n",
      "Epoch 42, CIFAR-10 Batch 3:  Train Loss:   0.0933 Valid Loss:   0.9226 Valid Accuracy: 0.706200 \n",
      "Epoch 42, CIFAR-10 Batch 4:  Train Loss:   0.0755 Valid Loss:   0.9041 Valid Accuracy: 0.706400 \n",
      "Epoch 42, CIFAR-10 Batch 5:  Train Loss:   0.0709 Valid Loss:   0.8663 Valid Accuracy: 0.719000 \n",
      "Epoch 43, CIFAR-10 Batch 1:  Train Loss:   0.0819 Valid Loss:   0.9295 Valid Accuracy: 0.710800 \n",
      "Epoch 43, CIFAR-10 Batch 2:  Train Loss:   0.0824 Valid Loss:   0.8970 Valid Accuracy: 0.711400 \n",
      "Epoch 43, CIFAR-10 Batch 3:  Train Loss:   0.0938 Valid Loss:   0.9887 Valid Accuracy: 0.698800 \n",
      "Epoch 43, CIFAR-10 Batch 4:  Train Loss:   0.0679 Valid Loss:   0.9095 Valid Accuracy: 0.708200 \n",
      "Epoch 43, CIFAR-10 Batch 5:  Train Loss:   0.0611 Valid Loss:   0.8666 Valid Accuracy: 0.720400 \n",
      "Epoch 44, CIFAR-10 Batch 1:  Train Loss:   0.0603 Valid Loss:   0.9372 Valid Accuracy: 0.718800 \n",
      "Epoch 44, CIFAR-10 Batch 2:  Train Loss:   0.0643 Valid Loss:   0.9021 Valid Accuracy: 0.713800 \n",
      "Epoch 44, CIFAR-10 Batch 3:  Train Loss:   0.0707 Valid Loss:   0.9266 Valid Accuracy: 0.714000 \n",
      "Epoch 44, CIFAR-10 Batch 4:  Train Loss:   0.0666 Valid Loss:   0.9121 Valid Accuracy: 0.705200 \n",
      "Epoch 44, CIFAR-10 Batch 5:  Train Loss:   0.0653 Valid Loss:   0.8820 Valid Accuracy: 0.721600 \n",
      "Epoch 45, CIFAR-10 Batch 1:  Train Loss:   0.0605 Valid Loss:   0.9377 Valid Accuracy: 0.715200 \n",
      "Epoch 45, CIFAR-10 Batch 2:  Train Loss:   0.0559 Valid Loss:   0.8820 Valid Accuracy: 0.713200 \n",
      "Epoch 45, CIFAR-10 Batch 3:  Train Loss:   0.0571 Valid Loss:   0.8736 Valid Accuracy: 0.720000 \n",
      "Epoch 45, CIFAR-10 Batch 4:  Train Loss:   0.0588 Valid Loss:   0.9382 Valid Accuracy: 0.704600 \n",
      "Epoch 45, CIFAR-10 Batch 5:  Train Loss:   0.0615 Valid Loss:   0.8963 Valid Accuracy: 0.723000 \n",
      "Epoch 46, CIFAR-10 Batch 1:  Train Loss:   0.0502 Valid Loss:   0.9369 Valid Accuracy: 0.718000 \n",
      "Epoch 46, CIFAR-10 Batch 2:  Train Loss:   0.0419 Valid Loss:   0.8943 Valid Accuracy: 0.725600 \n",
      "Epoch 46, CIFAR-10 Batch 3:  Train Loss:   0.0520 Valid Loss:   0.9133 Valid Accuracy: 0.717000 \n",
      "Epoch 46, CIFAR-10 Batch 4:  Train Loss:   0.0497 Valid Loss:   0.9558 Valid Accuracy: 0.706000 \n",
      "Epoch 46, CIFAR-10 Batch 5:  Train Loss:   0.0560 Valid Loss:   0.9129 Valid Accuracy: 0.711000 \n",
      "Epoch 47, CIFAR-10 Batch 1:  Train Loss:   0.0503 Valid Loss:   0.9535 Valid Accuracy: 0.718400 \n",
      "Epoch 47, CIFAR-10 Batch 2:  Train Loss:   0.0389 Valid Loss:   0.8695 Valid Accuracy: 0.721800 \n",
      "Epoch 47, CIFAR-10 Batch 3:  Train Loss:   0.0488 Valid Loss:   0.9828 Valid Accuracy: 0.703400 \n",
      "Epoch 47, CIFAR-10 Batch 4:  Train Loss:   0.0500 Valid Loss:   0.9578 Valid Accuracy: 0.704200 \n",
      "Epoch 47, CIFAR-10 Batch 5:  Train Loss:   0.0371 Valid Loss:   0.9114 Valid Accuracy: 0.720400 \n",
      "Epoch 48, CIFAR-10 Batch 1:  Train Loss:   0.0451 Valid Loss:   0.9574 Valid Accuracy: 0.714000 \n",
      "Epoch 48, CIFAR-10 Batch 2:  Train Loss:   0.0394 Valid Loss:   0.8753 Valid Accuracy: 0.722600 \n",
      "Epoch 48, CIFAR-10 Batch 3:  Train Loss:   0.0571 Valid Loss:   0.9917 Valid Accuracy: 0.701200 \n",
      "Epoch 48, CIFAR-10 Batch 4:  Train Loss:   0.0507 Valid Loss:   0.9347 Valid Accuracy: 0.708800 \n",
      "Epoch 48, CIFAR-10 Batch 5:  Train Loss:   0.0598 Valid Loss:   0.9411 Valid Accuracy: 0.708800 \n",
      "Epoch 49, CIFAR-10 Batch 1:  Train Loss:   0.0455 Valid Loss:   0.9458 Valid Accuracy: 0.716800 \n",
      "Epoch 49, CIFAR-10 Batch 2:  Train Loss:   0.0606 Valid Loss:   0.8934 Valid Accuracy: 0.719000 \n",
      "Epoch 49, CIFAR-10 Batch 3:  Train Loss:   0.0323 Valid Loss:   0.9300 Valid Accuracy: 0.714600 \n",
      "Epoch 49, CIFAR-10 Batch 4:  Train Loss:   0.0498 Valid Loss:   0.9313 Valid Accuracy: 0.707400 \n",
      "Epoch 49, CIFAR-10 Batch 5:  Train Loss:   0.0567 Valid Loss:   0.9455 Valid Accuracy: 0.708800 \n",
      "Epoch 50, CIFAR-10 Batch 1:  Train Loss:   0.0376 Valid Loss:   0.9379 Valid Accuracy: 0.720000 \n",
      "Epoch 50, CIFAR-10 Batch 2:  Train Loss:   0.0461 Valid Loss:   0.9164 Valid Accuracy: 0.719000 \n",
      "Epoch 50, CIFAR-10 Batch 3:  Train Loss:   0.0420 Valid Loss:   0.9643 Valid Accuracy: 0.711600 \n",
      "Epoch 50, CIFAR-10 Batch 4:  Train Loss:   0.0395 Valid Loss:   0.9237 Valid Accuracy: 0.716600 \n",
      "Epoch 50, CIFAR-10 Batch 5:  Train Loss:   0.0443 Valid Loss:   0.9560 Valid Accuracy: 0.714200 \n",
      "Epoch 51, CIFAR-10 Batch 1:  Train Loss:   0.0311 Valid Loss:   0.9589 Valid Accuracy: 0.716600 \n",
      "Epoch 51, CIFAR-10 Batch 2:  Train Loss:   0.0377 Valid Loss:   0.9156 Valid Accuracy: 0.719800 \n",
      "Epoch 51, CIFAR-10 Batch 3:  Train Loss:   0.0276 Valid Loss:   0.9606 Valid Accuracy: 0.718600 \n",
      "Epoch 51, CIFAR-10 Batch 4:  Train Loss:   0.0279 Valid Loss:   0.8938 Valid Accuracy: 0.722200 \n",
      "Epoch 51, CIFAR-10 Batch 5:  Train Loss:   0.0411 Valid Loss:   0.9662 Valid Accuracy: 0.711000 \n",
      "Epoch 52, CIFAR-10 Batch 1:  Train Loss:   0.0315 Valid Loss:   1.0002 Valid Accuracy: 0.712600 \n",
      "Epoch 52, CIFAR-10 Batch 2:  Train Loss:   0.0461 Valid Loss:   0.9560 Valid Accuracy: 0.710400 \n",
      "Epoch 52, CIFAR-10 Batch 3:  Train Loss:   0.0289 Valid Loss:   0.9849 Valid Accuracy: 0.711800 \n",
      "Epoch 52, CIFAR-10 Batch 4:  Train Loss:   0.0265 Valid Loss:   0.9350 Valid Accuracy: 0.725800 \n",
      "Epoch 52, CIFAR-10 Batch 5:  Train Loss:   0.0314 Valid Loss:   0.9435 Valid Accuracy: 0.714200 \n",
      "Epoch 53, CIFAR-10 Batch 1:  Train Loss:   0.0380 Valid Loss:   1.0111 Valid Accuracy: 0.710000 \n",
      "Epoch 53, CIFAR-10 Batch 2:  Train Loss:   0.0312 Valid Loss:   0.9361 Valid Accuracy: 0.715600 \n",
      "Epoch 53, CIFAR-10 Batch 3:  Train Loss:   0.0328 Valid Loss:   0.9803 Valid Accuracy: 0.712000 \n",
      "Epoch 53, CIFAR-10 Batch 4:  Train Loss:   0.0195 Valid Loss:   0.9328 Valid Accuracy: 0.723200 \n",
      "Epoch 53, CIFAR-10 Batch 5:  Train Loss:   0.0250 Valid Loss:   0.9509 Valid Accuracy: 0.720600 \n",
      "Epoch 54, CIFAR-10 Batch 1:  Train Loss:   0.0409 Valid Loss:   1.0529 Valid Accuracy: 0.710600 \n",
      "Epoch 54, CIFAR-10 Batch 2:  Train Loss:   0.0354 Valid Loss:   0.9371 Valid Accuracy: 0.715600 \n",
      "Epoch 54, CIFAR-10 Batch 3:  Train Loss:   0.0228 Valid Loss:   1.0089 Valid Accuracy: 0.718400 \n",
      "Epoch 54, CIFAR-10 Batch 4:  Train Loss:   0.0205 Valid Loss:   0.9342 Valid Accuracy: 0.729600 \n",
      "Epoch 54, CIFAR-10 Batch 5:  Train Loss:   0.0233 Valid Loss:   0.9428 Valid Accuracy: 0.719400 \n",
      "Epoch 55, CIFAR-10 Batch 1:  Train Loss:   0.0294 Valid Loss:   1.0716 Valid Accuracy: 0.708800 \n",
      "Epoch 55, CIFAR-10 Batch 2:  Train Loss:   0.0262 Valid Loss:   0.9027 Valid Accuracy: 0.730400 \n",
      "Epoch 55, CIFAR-10 Batch 3:  Train Loss:   0.0303 Valid Loss:   1.0862 Valid Accuracy: 0.701200 \n",
      "Epoch 55, CIFAR-10 Batch 4:  Train Loss:   0.0301 Valid Loss:   0.9330 Valid Accuracy: 0.723800 \n",
      "Epoch 55, CIFAR-10 Batch 5:  Train Loss:   0.0230 Valid Loss:   0.9449 Valid Accuracy: 0.728200 \n",
      "Epoch 56, CIFAR-10 Batch 1:  Train Loss:   0.0239 Valid Loss:   1.0317 Valid Accuracy: 0.720200 \n",
      "Epoch 56, CIFAR-10 Batch 2:  Train Loss:   0.0231 Valid Loss:   0.9416 Valid Accuracy: 0.714800 \n",
      "Epoch 56, CIFAR-10 Batch 3:  Train Loss:   0.0239 Valid Loss:   0.9314 Valid Accuracy: 0.723600 \n",
      "Epoch 56, CIFAR-10 Batch 4:  Train Loss:   0.0276 Valid Loss:   0.9477 Valid Accuracy: 0.722400 \n",
      "Epoch 56, CIFAR-10 Batch 5:  Train Loss:   0.0312 Valid Loss:   0.9321 Valid Accuracy: 0.717600 \n",
      "Epoch 57, CIFAR-10 Batch 1:  Train Loss:   0.0336 Valid Loss:   1.0649 Valid Accuracy: 0.705400 \n",
      "Epoch 57, CIFAR-10 Batch 2:  Train Loss:   0.0374 Valid Loss:   0.9422 Valid Accuracy: 0.713200 \n",
      "Epoch 57, CIFAR-10 Batch 3:  Train Loss:   0.0211 Valid Loss:   0.9346 Valid Accuracy: 0.719800 \n",
      "Epoch 57, CIFAR-10 Batch 4:  Train Loss:   0.0263 Valid Loss:   0.9800 Valid Accuracy: 0.718800 \n",
      "Epoch 57, CIFAR-10 Batch 5:  Train Loss:   0.0254 Valid Loss:   0.9841 Valid Accuracy: 0.709200 \n",
      "Epoch 58, CIFAR-10 Batch 1:  Train Loss:   0.0259 Valid Loss:   1.1171 Valid Accuracy: 0.696800 \n",
      "Epoch 58, CIFAR-10 Batch 2:  Train Loss:   0.0236 Valid Loss:   0.9550 Valid Accuracy: 0.720200 \n",
      "Epoch 58, CIFAR-10 Batch 3:  Train Loss:   0.0195 Valid Loss:   0.9027 Valid Accuracy: 0.731200 \n",
      "Epoch 58, CIFAR-10 Batch 4:  Train Loss:   0.0209 Valid Loss:   0.9444 Valid Accuracy: 0.724200 \n",
      "Epoch 58, CIFAR-10 Batch 5:  Train Loss:   0.0206 Valid Loss:   0.9622 Valid Accuracy: 0.716800 \n",
      "Epoch 59, CIFAR-10 Batch 1:  Train Loss:   0.0174 Valid Loss:   1.0292 Valid Accuracy: 0.714800 \n",
      "Epoch 59, CIFAR-10 Batch 2:  Train Loss:   0.0299 Valid Loss:   0.9991 Valid Accuracy: 0.703000 \n",
      "Epoch 59, CIFAR-10 Batch 3:  Train Loss:   0.0196 Valid Loss:   0.9072 Valid Accuracy: 0.725200 \n",
      "Epoch 59, CIFAR-10 Batch 4:  Train Loss:   0.0201 Valid Loss:   0.9947 Valid Accuracy: 0.721800 \n",
      "Epoch 59, CIFAR-10 Batch 5:  Train Loss:   0.0275 Valid Loss:   1.0090 Valid Accuracy: 0.715800 \n",
      "Epoch 60, CIFAR-10 Batch 1:  Train Loss:   0.0153 Valid Loss:   1.0436 Valid Accuracy: 0.713600 \n",
      "Epoch 60, CIFAR-10 Batch 2:  Train Loss:   0.0220 Valid Loss:   0.9363 Valid Accuracy: 0.719200 \n",
      "Epoch 60, CIFAR-10 Batch 3:  Train Loss:   0.0176 Valid Loss:   0.9265 Valid Accuracy: 0.724800 \n",
      "Epoch 60, CIFAR-10 Batch 4:  Train Loss:   0.0278 Valid Loss:   1.0000 Valid Accuracy: 0.714800 \n",
      "Epoch 60, CIFAR-10 Batch 5:  Train Loss:   0.0172 Valid Loss:   0.9700 Valid Accuracy: 0.717800 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7193014711141587\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEREREYn+P9K9TUf+pof6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d53752e470>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
