{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/cifar/cifar-10-python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 4:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1003, 1: 963, 2: 1041, 3: 976, 4: 1004, 5: 1021, 6: 1004, 7: 981, 8: 1024, 9: 983}\n",
      "First 20 Labels: [0, 6, 0, 2, 7, 2, 1, 2, 4, 1, 5, 6, 6, 3, 1, 3, 5, 5, 8, 1]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 13 Max Value: 169\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 2 Name: bird\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBD0ANCboAaAxQQ8AjQl6AGjs/wC42Lcq2cSEgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c6000a9978>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 4\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return x/256\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    result = np.zeros((len(x),10))\n",
    "    for i, label in enumerate(x):\n",
    "        result[i][label] = 1\n",
    "                              \n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))\n",
    "\n",
    "#valid_features[:1], valid_labels[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None,32,32,3], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.uint8, shape=[None, 10], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # Convolution Weights and Bias\n",
    "    conv_weights = tf.Variable(tf.truncated_normal([conv_ksize[1], conv_ksize[0], \n",
    "                                                  x_tensor.get_shape().as_list()[3], conv_num_outputs ],stddev=0.1))\n",
    "    conv_bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    # Convolution Layer\n",
    "    conv_layer=tf.nn.conv2d(x_tensor, conv_weights, strides=[1,conv_strides[1], conv_strides[0],1], padding='SAME')\n",
    "    conv_layer=tf.nn.bias_add(conv_layer,conv_bias)\n",
    "    conv_layer=tf.nn.relu(conv_layer)\n",
    "    \n",
    "    #Pooling Layer\n",
    "    pooling_layer=tf.nn.max_pool(conv_layer, ksize=[1,pool_ksize[1], pool_ksize[1],1], \n",
    "                                 strides=[1,pool_strides[1], pool_strides[0],1], padding='SAME')\n",
    "    \n",
    "    return pooling_layer \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape_l = x_tensor.get_shape().as_list()\n",
    "    fc1 = tf.reshape(x_tensor, shape=[-1, shape_l[1]*shape_l[2]*shape_l[3]])\n",
    "    return fc1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    shape_l = x_tensor.get_shape().as_list()\n",
    "    weights = tf.Variable(tf.truncated_normal([shape_l[1], num_outputs],stddev=0.1))\n",
    "    bias = tf.Variable(tf.random_normal([num_outputs]))\n",
    "\n",
    "    # Logits - xW + b\n",
    "    fc = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    fc = tf.nn.relu(fc)\n",
    "\n",
    "    return fc\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    shape_l = x_tensor.get_shape().as_list()\n",
    "    weights = tf.Variable(tf.truncated_normal([shape_l[1], num_outputs],stddev=0.1))\n",
    "    bias = tf.Variable(tf.random_normal([num_outputs]))\n",
    "\n",
    "    # Logits - xW + b\n",
    "    return tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape (?, 32, 32, 3)\n",
      "1st covnet shape (?, 16, 16, 16)\n",
      "2nd covnet shape (?, 8, 8, 64)\n",
      "3rd covnet shape (?, 4, 4, 256)\n",
      "Flatten shape (?, 4096)\n",
      "Fully Con 1 shape (?, 2048)\n",
      "Fully Con 2 shape (?, 1024)\n",
      "x shape (?, 32, 32, 3)\n",
      "1st covnet shape (?, 16, 16, 16)\n",
      "2nd covnet shape (?, 8, 8, 64)\n",
      "3rd covnet shape (?, 4, 4, 256)\n",
      "Flatten shape (?, 4096)\n",
      "Fully Con 1 shape (?, 2048)\n",
      "Fully Con 2 shape (?, 1024)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    # Layer 1 - 32*32*3 to 16*16*32\n",
    "\n",
    "    #cov_net = conv2d_maxpool(x, 16,(3,3), (2,2), (2,2), (1,1))\n",
    "    #cov_net = conv2d_maxpool(cov_net, 64,(2,2), (2,2), (2,2), (1,1))\n",
    "    #cov_net = conv2d_maxpool(cov_net, 256,(2,2), (2,2), (2,2), (1,1))\n",
    "\n",
    "    print (\"x shape {}\".format(x.get_shape()))\n",
    "\n",
    "    cov_net = conv2d_maxpool(x, 16,(2,2), (2,2), (2,2), (1,1))\n",
    "    print (\"1st covnet shape {}\".format(cov_net.get_shape()))\n",
    "    \n",
    "    cov_net = conv2d_maxpool(cov_net, 64,(2,2), (2,2), (2,2), (1,1))\n",
    "    print (\"2nd covnet shape {}\".format(cov_net.get_shape()))\n",
    "           \n",
    "    cov_net = conv2d_maxpool(cov_net, 256,(2,2), (2,2), (2,2), (1,1))\n",
    "    print (\"3rd covnet shape {}\".format(cov_net.get_shape()))\n",
    "           \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    cov_net=flatten(cov_net)\n",
    "    print (\"Flatten shape {}\".format(cov_net.get_shape()))\n",
    "    #cov_net = tf.nn.dropout(cov_net,keep_prob)    \n",
    "    \n",
    "    #print (cov_net.get_shape())\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    cov_net = fully_conn(cov_net, 2048)\n",
    "    print (\"Fully Con 1 shape {}\".format(cov_net.get_shape()))\n",
    "    \n",
    "    cov_net = tf.nn.dropout(cov_net,keep_prob)\n",
    "    cov_net = fully_conn(cov_net, 1024)   \n",
    "    print (\"Fully Con 2 shape {}\".format(cov_net.get_shape()))\n",
    "    \n",
    "    #cov_net = fully_conn(cov_net, 100)\n",
    "    #print (\"Fully Con 3 shape {}\".format(cov_net.get_shape()))\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    cov_net = output(cov_net,10)\n",
    "    # TODO: return output\n",
    "    return cov_net\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    t_loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "\n",
    "    v_loss = session.run(cost, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.})\n",
    "    v_acc = session.run(accuracy, feed_dict={\n",
    "        x: valid_features,\n",
    "        y: valid_labels,\n",
    "        keep_prob: 1.})    \n",
    "    print('Train Loss: {:>8.4f} Valid Loss: {:>8.4f} Valid Accuracy: {:.6f} '.format(\n",
    "        t_loss,\n",
    "        v_loss,\n",
    "        v_acc))\n",
    "    #sys.stdout.write(\"\\r\" + 'Epoch {:>2}, Batch {:>3} - Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "    #    epoch + 1,\n",
    "    #    batch + 1,\n",
    "    #    loss,\n",
    "    #    valid_acc))\n",
    "    #sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "keep_probability = 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Train Loss:   5.0433 Valid Loss:   5.0445 Valid Accuracy: 0.108400 \n",
      "Epoch  2, CIFAR-10 Batch 1:  Train Loss:   2.6334 Valid Loss:   2.5263 Valid Accuracy: 0.139600 \n",
      "Epoch  3, CIFAR-10 Batch 1:  Train Loss:   1.9975 Valid Loss:   1.8787 Valid Accuracy: 0.309400 \n",
      "Epoch  4, CIFAR-10 Batch 1:  Train Loss:   1.8256 Valid Loss:   1.7875 Valid Accuracy: 0.344600 \n",
      "Epoch  5, CIFAR-10 Batch 1:  Train Loss:   1.6917 Valid Loss:   1.6480 Valid Accuracy: 0.387200 \n",
      "Epoch  6, CIFAR-10 Batch 1:  Train Loss:   1.5671 Valid Loss:   1.5252 Valid Accuracy: 0.448800 \n",
      "Epoch  7, CIFAR-10 Batch 1:  Train Loss:   1.4874 Valid Loss:   1.4957 Valid Accuracy: 0.462800 \n",
      "Epoch  8, CIFAR-10 Batch 1:  Train Loss:   1.3985 Valid Loss:   1.4291 Valid Accuracy: 0.481600 \n",
      "Epoch  9, CIFAR-10 Batch 1:  Train Loss:   1.3509 Valid Loss:   1.4128 Valid Accuracy: 0.481000 \n",
      "Epoch 10, CIFAR-10 Batch 1:  Train Loss:   1.2878 Valid Loss:   1.3928 Valid Accuracy: 0.490200 \n",
      "Epoch 11, CIFAR-10 Batch 1:  Train Loss:   1.1974 Valid Loss:   1.3551 Valid Accuracy: 0.508400 \n",
      "Epoch 12, CIFAR-10 Batch 1:  Train Loss:   1.1497 Valid Loss:   1.3402 Valid Accuracy: 0.510400 \n",
      "Epoch 13, CIFAR-10 Batch 1:  Train Loss:   1.0859 Valid Loss:   1.3396 Valid Accuracy: 0.517000 \n",
      "Epoch 14, CIFAR-10 Batch 1:  Train Loss:   1.0327 Valid Loss:   1.2958 Valid Accuracy: 0.531800 \n",
      "Epoch 15, CIFAR-10 Batch 1:  Train Loss:   0.9730 Valid Loss:   1.3038 Valid Accuracy: 0.528200 \n",
      "Epoch 16, CIFAR-10 Batch 1:  Train Loss:   0.9288 Valid Loss:   1.3004 Valid Accuracy: 0.535800 \n",
      "Epoch 17, CIFAR-10 Batch 1:  Train Loss:   0.8577 Valid Loss:   1.2649 Valid Accuracy: 0.549800 \n",
      "Epoch 18, CIFAR-10 Batch 1:  Train Loss:   0.8044 Valid Loss:   1.2769 Valid Accuracy: 0.548600 \n",
      "Epoch 19, CIFAR-10 Batch 1:  Train Loss:   0.7571 Valid Loss:   1.2462 Valid Accuracy: 0.557200 \n",
      "Epoch 20, CIFAR-10 Batch 1:  Train Loss:   0.6668 Valid Loss:   1.2408 Valid Accuracy: 0.565600 \n",
      "Epoch 21, CIFAR-10 Batch 1:  Train Loss:   0.6111 Valid Loss:   1.2183 Valid Accuracy: 0.575600 \n",
      "Epoch 22, CIFAR-10 Batch 1:  Train Loss:   0.5669 Valid Loss:   1.2712 Valid Accuracy: 0.563000 \n",
      "Epoch 23, CIFAR-10 Batch 1:  Train Loss:   0.5345 Valid Loss:   1.2451 Valid Accuracy: 0.570800 \n",
      "Epoch 24, CIFAR-10 Batch 1:  Train Loss:   0.5054 Valid Loss:   1.2746 Valid Accuracy: 0.560000 \n",
      "Epoch 25, CIFAR-10 Batch 1:  Train Loss:   0.4677 Valid Loss:   1.3005 Valid Accuracy: 0.564200 \n",
      "Epoch 26, CIFAR-10 Batch 1:  Train Loss:   0.4379 Valid Loss:   1.3340 Valid Accuracy: 0.560200 \n",
      "Epoch 27, CIFAR-10 Batch 1:  Train Loss:   0.4757 Valid Loss:   1.4349 Valid Accuracy: 0.539200 \n",
      "Epoch 28, CIFAR-10 Batch 1:  Train Loss:   0.3988 Valid Loss:   1.3489 Valid Accuracy: 0.557800 \n",
      "Epoch 29, CIFAR-10 Batch 1:  Train Loss:   0.4096 Valid Loss:   1.3802 Valid Accuracy: 0.557200 \n",
      "Epoch 30, CIFAR-10 Batch 1:  Train Loss:   0.3920 Valid Loss:   1.4275 Valid Accuracy: 0.539000 \n",
      "Epoch 31, CIFAR-10 Batch 1:  Train Loss:   0.3336 Valid Loss:   1.3495 Valid Accuracy: 0.557800 \n",
      "Epoch 32, CIFAR-10 Batch 1:  Train Loss:   0.2864 Valid Loss:   1.3661 Valid Accuracy: 0.555600 \n",
      "Epoch 33, CIFAR-10 Batch 1:  Train Loss:   0.2453 Valid Loss:   1.3646 Valid Accuracy: 0.566200 \n",
      "Epoch 34, CIFAR-10 Batch 1:  Train Loss:   0.2658 Valid Loss:   1.4778 Valid Accuracy: 0.541400 \n",
      "Epoch 35, CIFAR-10 Batch 1:  Train Loss:   0.2224 Valid Loss:   1.4021 Valid Accuracy: 0.561800 \n",
      "Epoch 36, CIFAR-10 Batch 1:  Train Loss:   0.1871 Valid Loss:   1.4212 Valid Accuracy: 0.560200 \n",
      "Epoch 37, CIFAR-10 Batch 1:  Train Loss:   0.1653 Valid Loss:   1.4237 Valid Accuracy: 0.572600 \n",
      "Epoch 38, CIFAR-10 Batch 1:  Train Loss:   0.1242 Valid Loss:   1.3800 Valid Accuracy: 0.588000 \n",
      "Epoch 39, CIFAR-10 Batch 1:  Train Loss:   0.1215 Valid Loss:   1.4859 Valid Accuracy: 0.559800 \n",
      "Epoch 40, CIFAR-10 Batch 1:  Train Loss:   0.1212 Valid Loss:   1.4970 Valid Accuracy: 0.567200 \n",
      "Epoch 41, CIFAR-10 Batch 1:  Train Loss:   0.1318 Valid Loss:   1.6406 Valid Accuracy: 0.553800 \n",
      "Epoch 42, CIFAR-10 Batch 1:  Train Loss:   0.0954 Valid Loss:   1.5276 Valid Accuracy: 0.575200 \n",
      "Epoch 43, CIFAR-10 Batch 1:  Train Loss:   0.1002 Valid Loss:   1.6169 Valid Accuracy: 0.558000 \n",
      "Epoch 44, CIFAR-10 Batch 1:  Train Loss:   0.0626 Valid Loss:   1.6529 Valid Accuracy: 0.561200 \n",
      "Epoch 45, CIFAR-10 Batch 1:  Train Loss:   0.0742 Valid Loss:   1.7660 Valid Accuracy: 0.553200 \n",
      "Epoch 46, CIFAR-10 Batch 1:  Train Loss:   0.0695 Valid Loss:   1.7446 Valid Accuracy: 0.557600 \n",
      "Epoch 47, CIFAR-10 Batch 1:  Train Loss:   0.0638 Valid Loss:   1.6025 Valid Accuracy: 0.578400 \n",
      "Epoch 48, CIFAR-10 Batch 1:  Train Loss:   0.0617 Valid Loss:   1.6738 Valid Accuracy: 0.570000 \n",
      "Epoch 49, CIFAR-10 Batch 1:  Train Loss:   0.0844 Valid Loss:   1.8272 Valid Accuracy: 0.555800 \n",
      "Epoch 50, CIFAR-10 Batch 1:  Train Loss:   0.1116 Valid Loss:   2.0354 Valid Accuracy: 0.531800 \n",
      "Epoch 51, CIFAR-10 Batch 1:  Train Loss:   0.0470 Valid Loss:   1.7726 Valid Accuracy: 0.561600 \n",
      "Epoch 52, CIFAR-10 Batch 1:  Train Loss:   0.0442 Valid Loss:   1.6769 Valid Accuracy: 0.574200 \n",
      "Epoch 53, CIFAR-10 Batch 1:  Train Loss:   0.0571 Valid Loss:   2.0146 Valid Accuracy: 0.562800 \n",
      "Epoch 54, CIFAR-10 Batch 1:  Train Loss:   0.0520 Valid Loss:   2.1088 Valid Accuracy: 0.545800 \n",
      "Epoch 55, CIFAR-10 Batch 1:  Train Loss:   0.0480 Valid Loss:   2.0846 Valid Accuracy: 0.549600 \n",
      "Epoch 56, CIFAR-10 Batch 1:  Train Loss:   0.1065 Valid Loss:   2.3062 Valid Accuracy: 0.532000 \n",
      "Epoch 57, CIFAR-10 Batch 1:  Train Loss:   0.0959 Valid Loss:   2.2370 Valid Accuracy: 0.530800 \n",
      "Epoch 58, CIFAR-10 Batch 1:  Train Loss:   0.0501 Valid Loss:   1.9042 Valid Accuracy: 0.543000 \n",
      "Epoch 59, CIFAR-10 Batch 1:  Train Loss:   0.0701 Valid Loss:   1.9642 Valid Accuracy: 0.556000 \n",
      "Epoch 60, CIFAR-10 Batch 1:  Train Loss:   0.0364 Valid Loss:   1.8810 Valid Accuracy: 0.575000 \n",
      "Epoch 61, CIFAR-10 Batch 1:  Train Loss:   0.0417 Valid Loss:   1.8822 Valid Accuracy: 0.569000 \n",
      "Epoch 62, CIFAR-10 Batch 1:  Train Loss:   0.0335 Valid Loss:   1.8593 Valid Accuracy: 0.582000 \n",
      "Epoch 63, CIFAR-10 Batch 1:  Train Loss:   0.0217 Valid Loss:   1.9010 Valid Accuracy: 0.587400 \n",
      "Epoch 64, CIFAR-10 Batch 1:  Train Loss:   0.0085 Valid Loss:   1.8190 Valid Accuracy: 0.593600 \n",
      "Epoch 65, CIFAR-10 Batch 1:  Train Loss:   0.0102 Valid Loss:   1.8868 Valid Accuracy: 0.588600 \n",
      "Epoch 66, CIFAR-10 Batch 1:  Train Loss:   0.0060 Valid Loss:   1.9236 Valid Accuracy: 0.584800 \n",
      "Epoch 67, CIFAR-10 Batch 1:  Train Loss:   0.0090 Valid Loss:   2.0527 Valid Accuracy: 0.572400 \n",
      "Epoch 68, CIFAR-10 Batch 1:  Train Loss:   0.0176 Valid Loss:   2.1847 Valid Accuracy: 0.558000 \n",
      "Epoch 69, CIFAR-10 Batch 1:  Train Loss:   0.0048 Valid Loss:   1.9850 Valid Accuracy: 0.582200 \n",
      "Epoch 70, CIFAR-10 Batch 1:  Train Loss:   0.0066 Valid Loss:   1.9567 Valid Accuracy: 0.590800 \n",
      "Epoch 71, CIFAR-10 Batch 1:  Train Loss:   0.0024 Valid Loss:   1.9354 Valid Accuracy: 0.593800 \n",
      "Epoch 72, CIFAR-10 Batch 1:  Train Loss:   0.0025 Valid Loss:   2.0109 Valid Accuracy: 0.602200 \n",
      "Epoch 73, CIFAR-10 Batch 1:  Train Loss:   0.0021 Valid Loss:   2.0311 Valid Accuracy: 0.601400 \n",
      "Epoch 74, CIFAR-10 Batch 1:  Train Loss:   0.0022 Valid Loss:   2.0598 Valid Accuracy: 0.600600 \n",
      "Epoch 75, CIFAR-10 Batch 1:  Train Loss:   0.0021 Valid Loss:   2.1282 Valid Accuracy: 0.598600 \n",
      "Epoch 76, CIFAR-10 Batch 1:  Train Loss:   0.0020 Valid Loss:   2.1771 Valid Accuracy: 0.594800 \n",
      "Epoch 77, CIFAR-10 Batch 1:  Train Loss:   0.0020 Valid Loss:   2.1375 Valid Accuracy: 0.596200 \n",
      "Epoch 78, CIFAR-10 Batch 1:  Train Loss:   0.0017 Valid Loss:   2.1279 Valid Accuracy: 0.595600 \n",
      "Epoch 79, CIFAR-10 Batch 1:  Train Loss:   0.0014 Valid Loss:   2.1388 Valid Accuracy: 0.597800 \n",
      "Epoch 80, CIFAR-10 Batch 1:  Train Loss:   0.0010 Valid Loss:   2.1543 Valid Accuracy: 0.597800 \n",
      "Epoch 81, CIFAR-10 Batch 1:  Train Loss:   0.0012 Valid Loss:   2.2052 Valid Accuracy: 0.600400 \n",
      "Epoch 82, CIFAR-10 Batch 1:  Train Loss:   0.0012 Valid Loss:   2.1831 Valid Accuracy: 0.599800 \n",
      "Epoch 83, CIFAR-10 Batch 1:  Train Loss:   0.0020 Valid Loss:   2.1954 Valid Accuracy: 0.600200 \n",
      "Epoch 84, CIFAR-10 Batch 1:  Train Loss:   0.0016 Valid Loss:   2.2501 Valid Accuracy: 0.599200 \n",
      "Epoch 85, CIFAR-10 Batch 1:  Train Loss:   0.0014 Valid Loss:   2.2562 Valid Accuracy: 0.591000 \n",
      "Epoch 86, CIFAR-10 Batch 1:  Train Loss:   0.0016 Valid Loss:   2.2497 Valid Accuracy: 0.596000 \n",
      "Epoch 87, CIFAR-10 Batch 1:  Train Loss:   0.0017 Valid Loss:   2.3778 Valid Accuracy: 0.585600 \n",
      "Epoch 88, CIFAR-10 Batch 1:  Train Loss:   0.0011 Valid Loss:   2.2894 Valid Accuracy: 0.590600 \n",
      "Epoch 89, CIFAR-10 Batch 1:  Train Loss:   0.0011 Valid Loss:   2.3646 Valid Accuracy: 0.590400 \n",
      "Epoch 90, CIFAR-10 Batch 1:  Train Loss:   0.0008 Valid Loss:   2.2999 Valid Accuracy: 0.594800 \n",
      "Epoch 91, CIFAR-10 Batch 1:  Train Loss:   0.0013 Valid Loss:   2.3929 Valid Accuracy: 0.589200 \n",
      "Epoch 92, CIFAR-10 Batch 1:  Train Loss:   0.0008 Valid Loss:   2.3308 Valid Accuracy: 0.595000 \n",
      "Epoch 93, CIFAR-10 Batch 1:  Train Loss:   0.0018 Valid Loss:   2.4280 Valid Accuracy: 0.583000 \n",
      "Epoch 94, CIFAR-10 Batch 1:  Train Loss:   0.0011 Valid Loss:   2.3628 Valid Accuracy: 0.589600 \n",
      "Epoch 95, CIFAR-10 Batch 1:  Train Loss:   0.0008 Valid Loss:   2.3520 Valid Accuracy: 0.591600 \n",
      "Epoch 96, CIFAR-10 Batch 1:  Train Loss:   0.0009 Valid Loss:   2.3789 Valid Accuracy: 0.590200 \n",
      "Epoch 97, CIFAR-10 Batch 1:  Train Loss:   0.0011 Valid Loss:   2.4044 Valid Accuracy: 0.592600 \n",
      "Epoch 98, CIFAR-10 Batch 1:  Train Loss:   0.0010 Valid Loss:   2.3492 Valid Accuracy: 0.594800 \n",
      "Epoch 99, CIFAR-10 Batch 1:  Train Loss:   0.0005 Valid Loss:   2.3674 Valid Accuracy: 0.594400 \n",
      "Epoch 100, CIFAR-10 Batch 1:  Train Loss:   0.0016 Valid Loss:   2.5011 Valid Accuracy: 0.583800 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Train Loss:   2.5458 Valid Loss:   2.4889 Valid Accuracy: 0.113000 \n",
      "Epoch  1, CIFAR-10 Batch 2:  Train Loss:   2.1991 Valid Loss:   2.1986 Valid Accuracy: 0.169000 \n",
      "Epoch  1, CIFAR-10 Batch 3:  Train Loss:   1.8329 Valid Loss:   1.8951 Valid Accuracy: 0.311400 \n",
      "Epoch  1, CIFAR-10 Batch 4:  Train Loss:   1.6359 Valid Loss:   1.7232 Valid Accuracy: 0.395200 \n",
      "Epoch  1, CIFAR-10 Batch 5:  Train Loss:   1.5729 Valid Loss:   1.5896 Valid Accuracy: 0.438600 \n",
      "Epoch  2, CIFAR-10 Batch 1:  Train Loss:   1.6385 Valid Loss:   1.5983 Valid Accuracy: 0.443400 \n",
      "Epoch  2, CIFAR-10 Batch 2:  Train Loss:   1.4014 Valid Loss:   1.4557 Valid Accuracy: 0.480600 \n",
      "Epoch  2, CIFAR-10 Batch 3:  Train Loss:   1.2498 Valid Loss:   1.3854 Valid Accuracy: 0.512400 \n",
      "Epoch  2, CIFAR-10 Batch 4:  Train Loss:   1.2727 Valid Loss:   1.4027 Valid Accuracy: 0.497400 \n",
      "Epoch  2, CIFAR-10 Batch 5:  Train Loss:   1.2704 Valid Loss:   1.3214 Valid Accuracy: 0.524800 \n",
      "Epoch  3, CIFAR-10 Batch 1:  Train Loss:   1.3711 Valid Loss:   1.3793 Valid Accuracy: 0.527600 \n",
      "Epoch  3, CIFAR-10 Batch 2:  Train Loss:   1.2151 Valid Loss:   1.2870 Valid Accuracy: 0.545400 \n",
      "Epoch  3, CIFAR-10 Batch 3:  Train Loss:   1.0991 Valid Loss:   1.2421 Valid Accuracy: 0.557400 \n",
      "Epoch  3, CIFAR-10 Batch 4:  Train Loss:   1.0536 Valid Loss:   1.2214 Valid Accuracy: 0.563400 \n",
      "Epoch  3, CIFAR-10 Batch 5:  Train Loss:   1.0701 Valid Loss:   1.1716 Valid Accuracy: 0.588400 \n",
      "Epoch  4, CIFAR-10 Batch 1:  Train Loss:   1.1845 Valid Loss:   1.2259 Valid Accuracy: 0.565000 \n",
      "Epoch  4, CIFAR-10 Batch 2:  Train Loss:   1.0680 Valid Loss:   1.1687 Valid Accuracy: 0.587800 \n",
      "Epoch  4, CIFAR-10 Batch 3:  Train Loss:   0.9510 Valid Loss:   1.1521 Valid Accuracy: 0.585600 \n",
      "Epoch  4, CIFAR-10 Batch 4:  Train Loss:   0.9176 Valid Loss:   1.1222 Valid Accuracy: 0.602200 \n",
      "Epoch  4, CIFAR-10 Batch 5:  Train Loss:   0.9246 Valid Loss:   1.0812 Valid Accuracy: 0.619000 \n",
      "Epoch  5, CIFAR-10 Batch 1:  Train Loss:   1.0453 Valid Loss:   1.1448 Valid Accuracy: 0.590800 \n",
      "Epoch  5, CIFAR-10 Batch 2:  Train Loss:   0.9412 Valid Loss:   1.0730 Valid Accuracy: 0.624000 \n",
      "Epoch  5, CIFAR-10 Batch 3:  Train Loss:   0.8334 Valid Loss:   1.0841 Valid Accuracy: 0.614600 \n",
      "Epoch  5, CIFAR-10 Batch 4:  Train Loss:   0.7986 Valid Loss:   1.0491 Valid Accuracy: 0.629600 \n",
      "Epoch  5, CIFAR-10 Batch 5:  Train Loss:   0.8107 Valid Loss:   1.0290 Valid Accuracy: 0.644000 \n",
      "Epoch  6, CIFAR-10 Batch 1:  Train Loss:   0.9097 Valid Loss:   1.0731 Valid Accuracy: 0.613000 \n",
      "Epoch  6, CIFAR-10 Batch 2:  Train Loss:   0.8301 Valid Loss:   1.0320 Valid Accuracy: 0.638600 \n",
      "Epoch  6, CIFAR-10 Batch 3:  Train Loss:   0.7432 Valid Loss:   1.0591 Valid Accuracy: 0.626400 \n",
      "Epoch  6, CIFAR-10 Batch 4:  Train Loss:   0.7224 Valid Loss:   1.0226 Valid Accuracy: 0.639800 \n",
      "Epoch  6, CIFAR-10 Batch 5:  Train Loss:   0.7327 Valid Loss:   1.0082 Valid Accuracy: 0.649000 \n",
      "Epoch  7, CIFAR-10 Batch 1:  Train Loss:   0.7865 Valid Loss:   1.0289 Valid Accuracy: 0.636600 \n",
      "Epoch  7, CIFAR-10 Batch 2:  Train Loss:   0.7476 Valid Loss:   1.0049 Valid Accuracy: 0.649800 \n",
      "Epoch  7, CIFAR-10 Batch 3:  Train Loss:   0.7076 Valid Loss:   1.1214 Valid Accuracy: 0.610600 \n",
      "Epoch  7, CIFAR-10 Batch 4:  Train Loss:   0.6567 Valid Loss:   1.0040 Valid Accuracy: 0.651400 \n",
      "Epoch  7, CIFAR-10 Batch 5:  Train Loss:   0.6311 Valid Loss:   0.9698 Valid Accuracy: 0.666000 \n",
      "Epoch  8, CIFAR-10 Batch 1:  Train Loss:   0.7131 Valid Loss:   1.0668 Valid Accuracy: 0.630800 \n",
      "Epoch  8, CIFAR-10 Batch 2:  Train Loss:   0.6424 Valid Loss:   0.9718 Valid Accuracy: 0.659800 \n",
      "Epoch  8, CIFAR-10 Batch 3:  Train Loss:   0.5647 Valid Loss:   1.0332 Valid Accuracy: 0.636200 \n",
      "Epoch  8, CIFAR-10 Batch 4:  Train Loss:   0.6057 Valid Loss:   1.0058 Valid Accuracy: 0.658400 \n",
      "Epoch  8, CIFAR-10 Batch 5:  Train Loss:   0.5796 Valid Loss:   0.9896 Valid Accuracy: 0.653200 \n",
      "Epoch  9, CIFAR-10 Batch 1:  Train Loss:   0.5920 Valid Loss:   0.9907 Valid Accuracy: 0.655000 \n",
      "Epoch  9, CIFAR-10 Batch 2:  Train Loss:   0.5570 Valid Loss:   0.9590 Valid Accuracy: 0.667600 \n",
      "Epoch  9, CIFAR-10 Batch 3:  Train Loss:   0.4915 Valid Loss:   1.0399 Valid Accuracy: 0.644000 \n",
      "Epoch  9, CIFAR-10 Batch 4:  Train Loss:   0.5898 Valid Loss:   1.0493 Valid Accuracy: 0.634200 \n",
      "Epoch  9, CIFAR-10 Batch 5:  Train Loss:   0.5132 Valid Loss:   0.9700 Valid Accuracy: 0.661200 \n",
      "Epoch 10, CIFAR-10 Batch 1:  Train Loss:   0.4995 Valid Loss:   0.9612 Valid Accuracy: 0.667000 \n",
      "Epoch 10, CIFAR-10 Batch 2:  Train Loss:   0.5001 Valid Loss:   0.9537 Valid Accuracy: 0.668200 \n",
      "Epoch 10, CIFAR-10 Batch 3:  Train Loss:   0.4693 Valid Loss:   1.0814 Valid Accuracy: 0.637600 \n",
      "Epoch 10, CIFAR-10 Batch 4:  Train Loss:   0.5464 Valid Loss:   1.1013 Valid Accuracy: 0.630800 \n",
      "Epoch 10, CIFAR-10 Batch 5:  Train Loss:   0.4397 Valid Loss:   0.9483 Valid Accuracy: 0.672600 \n",
      "Epoch 11, CIFAR-10 Batch 1:  Train Loss:   0.4625 Valid Loss:   0.9764 Valid Accuracy: 0.665800 \n",
      "Epoch 11, CIFAR-10 Batch 2:  Train Loss:   0.4779 Valid Loss:   1.0649 Valid Accuracy: 0.636800 \n",
      "Epoch 11, CIFAR-10 Batch 3:  Train Loss:   0.4300 Valid Loss:   1.0680 Valid Accuracy: 0.642600 \n",
      "Epoch 11, CIFAR-10 Batch 4:  Train Loss:   0.4650 Valid Loss:   1.0590 Valid Accuracy: 0.643800 \n",
      "Epoch 11, CIFAR-10 Batch 5:  Train Loss:   0.3473 Valid Loss:   0.9337 Valid Accuracy: 0.677000 \n",
      "Epoch 12, CIFAR-10 Batch 1:  Train Loss:   0.3621 Valid Loss:   0.9615 Valid Accuracy: 0.673400 \n",
      "Epoch 12, CIFAR-10 Batch 2:  Train Loss:   0.4214 Valid Loss:   1.1669 Valid Accuracy: 0.620800 \n",
      "Epoch 12, CIFAR-10 Batch 3:  Train Loss:   0.3116 Valid Loss:   0.9769 Valid Accuracy: 0.679600 \n",
      "Epoch 12, CIFAR-10 Batch 4:  Train Loss:   0.3819 Valid Loss:   1.0598 Valid Accuracy: 0.640000 \n",
      "Epoch 12, CIFAR-10 Batch 5:  Train Loss:   0.3019 Valid Loss:   0.9942 Valid Accuracy: 0.671400 \n",
      "Epoch 13, CIFAR-10 Batch 1:  Train Loss:   0.3347 Valid Loss:   1.0162 Valid Accuracy: 0.666200 \n",
      "Epoch 13, CIFAR-10 Batch 2:  Train Loss:   0.3111 Valid Loss:   1.0222 Valid Accuracy: 0.662000 \n",
      "Epoch 13, CIFAR-10 Batch 3:  Train Loss:   0.2777 Valid Loss:   0.9710 Valid Accuracy: 0.675800 \n",
      "Epoch 13, CIFAR-10 Batch 4:  Train Loss:   0.3106 Valid Loss:   1.0584 Valid Accuracy: 0.651000 \n",
      "Epoch 13, CIFAR-10 Batch 5:  Train Loss:   0.2672 Valid Loss:   1.0675 Valid Accuracy: 0.666400 \n",
      "Epoch 14, CIFAR-10 Batch 1:  Train Loss:   0.2879 Valid Loss:   1.0262 Valid Accuracy: 0.668400 \n",
      "Epoch 14, CIFAR-10 Batch 2:  Train Loss:   0.3245 Valid Loss:   1.0839 Valid Accuracy: 0.653200 \n",
      "Epoch 14, CIFAR-10 Batch 3:  Train Loss:   0.2921 Valid Loss:   1.1506 Valid Accuracy: 0.645600 \n",
      "Epoch 14, CIFAR-10 Batch 4:  Train Loss:   0.2699 Valid Loss:   1.0796 Valid Accuracy: 0.651800 \n",
      "Epoch 14, CIFAR-10 Batch 5:  Train Loss:   0.2582 Valid Loss:   1.1240 Valid Accuracy: 0.649200 \n",
      "Epoch 15, CIFAR-10 Batch 1:  Train Loss:   0.2889 Valid Loss:   1.0845 Valid Accuracy: 0.670400 \n",
      "Epoch 15, CIFAR-10 Batch 2:  Train Loss:   0.2413 Valid Loss:   1.1006 Valid Accuracy: 0.658600 \n",
      "Epoch 15, CIFAR-10 Batch 3:  Train Loss:   0.2714 Valid Loss:   1.2897 Valid Accuracy: 0.619000 \n",
      "Epoch 15, CIFAR-10 Batch 4:  Train Loss:   0.2710 Valid Loss:   1.1752 Valid Accuracy: 0.637400 \n",
      "Epoch 15, CIFAR-10 Batch 5:  Train Loss:   0.2180 Valid Loss:   1.0603 Valid Accuracy: 0.665400 \n",
      "Epoch 16, CIFAR-10 Batch 1:  Train Loss:   0.2212 Valid Loss:   1.1103 Valid Accuracy: 0.660600 \n",
      "Epoch 16, CIFAR-10 Batch 2:  Train Loss:   0.1907 Valid Loss:   1.0676 Valid Accuracy: 0.676400 \n",
      "Epoch 16, CIFAR-10 Batch 3:  Train Loss:   0.1790 Valid Loss:   1.1395 Valid Accuracy: 0.658400 \n",
      "Epoch 16, CIFAR-10 Batch 4:  Train Loss:   0.2561 Valid Loss:   1.2623 Valid Accuracy: 0.613400 \n",
      "Epoch 16, CIFAR-10 Batch 5:  Train Loss:   0.1632 Valid Loss:   1.0874 Valid Accuracy: 0.668200 \n",
      "Epoch 17, CIFAR-10 Batch 1:  Train Loss:   0.2047 Valid Loss:   1.2127 Valid Accuracy: 0.650200 \n",
      "Epoch 17, CIFAR-10 Batch 2:  Train Loss:   0.1413 Valid Loss:   1.0671 Valid Accuracy: 0.686800 \n",
      "Epoch 17, CIFAR-10 Batch 3:  Train Loss:   0.1764 Valid Loss:   1.1389 Valid Accuracy: 0.665600 \n",
      "Epoch 17, CIFAR-10 Batch 4:  Train Loss:   0.1591 Valid Loss:   1.1398 Valid Accuracy: 0.655600 \n",
      "Epoch 17, CIFAR-10 Batch 5:  Train Loss:   0.1715 Valid Loss:   1.0674 Valid Accuracy: 0.669400 \n",
      "Epoch 18, CIFAR-10 Batch 1:  Train Loss:   0.1435 Valid Loss:   1.1468 Valid Accuracy: 0.668200 \n",
      "Epoch 18, CIFAR-10 Batch 2:  Train Loss:   0.1576 Valid Loss:   1.2177 Valid Accuracy: 0.656000 \n",
      "Epoch 18, CIFAR-10 Batch 3:  Train Loss:   0.1420 Valid Loss:   1.1767 Valid Accuracy: 0.667000 \n",
      "Epoch 18, CIFAR-10 Batch 4:  Train Loss:   0.1824 Valid Loss:   1.1999 Valid Accuracy: 0.643800 \n",
      "Epoch 18, CIFAR-10 Batch 5:  Train Loss:   0.1965 Valid Loss:   1.3042 Valid Accuracy: 0.626600 \n",
      "Epoch 19, CIFAR-10 Batch 1:  Train Loss:   0.1451 Valid Loss:   1.1995 Valid Accuracy: 0.664400 \n",
      "Epoch 19, CIFAR-10 Batch 2:  Train Loss:   0.1300 Valid Loss:   1.1709 Valid Accuracy: 0.666800 \n",
      "Epoch 19, CIFAR-10 Batch 3:  Train Loss:   0.1478 Valid Loss:   1.1663 Valid Accuracy: 0.666200 \n",
      "Epoch 19, CIFAR-10 Batch 4:  Train Loss:   0.1217 Valid Loss:   1.2069 Valid Accuracy: 0.659000 \n",
      "Epoch 19, CIFAR-10 Batch 5:  Train Loss:   0.1328 Valid Loss:   1.3451 Valid Accuracy: 0.640400 \n",
      "Epoch 20, CIFAR-10 Batch 1:  Train Loss:   0.1282 Valid Loss:   1.2219 Valid Accuracy: 0.661800 \n",
      "Epoch 20, CIFAR-10 Batch 2:  Train Loss:   0.1468 Valid Loss:   1.4488 Valid Accuracy: 0.616000 \n",
      "Epoch 20, CIFAR-10 Batch 3:  Train Loss:   0.0963 Valid Loss:   1.2400 Valid Accuracy: 0.663800 \n",
      "Epoch 20, CIFAR-10 Batch 4:  Train Loss:   0.0897 Valid Loss:   1.2021 Valid Accuracy: 0.668200 \n",
      "Epoch 20, CIFAR-10 Batch 5:  Train Loss:   0.0853 Valid Loss:   1.2219 Valid Accuracy: 0.670000 \n",
      "Epoch 21, CIFAR-10 Batch 1:  Train Loss:   0.0853 Valid Loss:   1.1885 Valid Accuracy: 0.680800 \n",
      "Epoch 21, CIFAR-10 Batch 2:  Train Loss:   0.0978 Valid Loss:   1.3302 Valid Accuracy: 0.639800 \n",
      "Epoch 21, CIFAR-10 Batch 3:  Train Loss:   0.0872 Valid Loss:   1.2451 Valid Accuracy: 0.670800 \n",
      "Epoch 21, CIFAR-10 Batch 4:  Train Loss:   0.0715 Valid Loss:   1.2986 Valid Accuracy: 0.657400 \n",
      "Epoch 21, CIFAR-10 Batch 5:  Train Loss:   0.0807 Valid Loss:   1.2617 Valid Accuracy: 0.674600 \n",
      "Epoch 22, CIFAR-10 Batch 1:  Train Loss:   0.0962 Valid Loss:   1.3520 Valid Accuracy: 0.663600 \n",
      "Epoch 22, CIFAR-10 Batch 2:  Train Loss:   0.1039 Valid Loss:   1.3937 Valid Accuracy: 0.653200 \n",
      "Epoch 22, CIFAR-10 Batch 3:  Train Loss:   0.0933 Valid Loss:   1.3991 Valid Accuracy: 0.652800 \n",
      "Epoch 22, CIFAR-10 Batch 4:  Train Loss:   0.0625 Valid Loss:   1.3184 Valid Accuracy: 0.673800 \n",
      "Epoch 22, CIFAR-10 Batch 5:  Train Loss:   0.0590 Valid Loss:   1.3943 Valid Accuracy: 0.667400 \n",
      "Epoch 23, CIFAR-10 Batch 1:  Train Loss:   0.0811 Valid Loss:   1.4175 Valid Accuracy: 0.658000 \n",
      "Epoch 23, CIFAR-10 Batch 2:  Train Loss:   0.0975 Valid Loss:   1.4309 Valid Accuracy: 0.634800 \n",
      "Epoch 23, CIFAR-10 Batch 3:  Train Loss:   0.0558 Valid Loss:   1.3148 Valid Accuracy: 0.664600 \n",
      "Epoch 23, CIFAR-10 Batch 4:  Train Loss:   0.0611 Valid Loss:   1.2927 Valid Accuracy: 0.678800 \n",
      "Epoch 23, CIFAR-10 Batch 5:  Train Loss:   0.0357 Valid Loss:   1.2835 Valid Accuracy: 0.688200 \n",
      "Epoch 24, CIFAR-10 Batch 1:  Train Loss:   0.0546 Valid Loss:   1.3856 Valid Accuracy: 0.673400 \n",
      "Epoch 24, CIFAR-10 Batch 2:  Train Loss:   0.0591 Valid Loss:   1.3433 Valid Accuracy: 0.661200 \n",
      "Epoch 24, CIFAR-10 Batch 3:  Train Loss:   0.0665 Valid Loss:   1.4027 Valid Accuracy: 0.662600 \n",
      "Epoch 24, CIFAR-10 Batch 4:  Train Loss:   0.0481 Valid Loss:   1.3650 Valid Accuracy: 0.668400 \n",
      "Epoch 24, CIFAR-10 Batch 5:  Train Loss:   0.0425 Valid Loss:   1.3209 Valid Accuracy: 0.683000 \n",
      "Epoch 25, CIFAR-10 Batch 1:  Train Loss:   0.0341 Valid Loss:   1.4091 Valid Accuracy: 0.681200 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-9df3032ebe9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_preprocess_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {:>2}, CIFAR-10 Batch {}:  '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-6c487fc505ef>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(session, optimizer, keep_probability, feature_batch, label_batch)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[1;31m# TODO: Implement Function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfeature_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\Tom\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\Tom\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\Tom\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32md:\\Tom\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\Tom\\Anaconda3\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
